"""
ã™ã‚ã—ç¤¾é•· Xãƒã‚¹ãƒˆä½œæˆãƒ„ãƒ¼ãƒ«
YouTubeã€Œå¤§äººã®å­¦ã³ç›´ã—TVã€ã®ã™ã‚ã—ç¤¾é•·ç”¨ XæŠ•ç¨¿ç”ŸæˆWebã‚¢ãƒ—ãƒª

ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼:
  1. ãƒœã‚¿ãƒ³ä¸€ã¤ã§ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’è‡ªå‹•å–å¾—
  2. AIãŒã™ã‚ã—ç¤¾é•·å‘ãã®ãƒˆãƒ”ãƒƒã‚¯ã‚’ãŠã™ã™ã‚
  3. é¸æŠã—ã¦é–¢é€£æƒ…å ±ã‚’è‡ªå‹•åé›†
  4. é«˜å“è³ªãªãƒã‚¹ãƒˆã‚’ç”Ÿæˆ
"""

import streamlit as st
import anthropic
import json
import os
import re
import io
import base64
import feedparser
import urllib.parse
import urllib.request
from dotenv import load_dotenv
from x_scraper import fetch_x_news_trends, login_to_x, is_logged_in, clear_session, _is_cloud_environment
from datetime import datetime
from pathlib import Path

# .env ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰APIã‚­ãƒ¼ã‚’è‡ªå‹•èª­ã¿è¾¼ã¿ï¼ˆæ—¢å­˜ã®ç©ºå¤‰æ•°ã‚‚ä¸Šæ›¸ãï¼‰
load_dotenv(Path(__file__).parent / ".env", override=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# å®šæ•°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
APP_DIR = Path(__file__).parent
HISTORY_DIR = APP_DIR / "history"
HISTORY_DIR.mkdir(exist_ok=True)
SYSTEM_PROMPT_PATH = APP_DIR / "suasi_system_prompt.md"
CLAUDE_MODEL = "claude-sonnet-4-20250514"
X_TRENDS_CACHE = APP_DIR / "x_trends_cache.json"
AUTOSAVE_PATH = Path("/tmp/x_post_tool_autosave.json")

# è‡ªå‹•ä¿å­˜å¯¾è±¡ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚­ãƒ¼
_AUTOSAVE_KEYS = [
    # ãƒˆãƒ¬ãƒ³ãƒ‰ã‚¿ãƒ–
    "trend_result", "trend_result_original", "trend_corrections_applied",
    "trend_factcheck", "trend_revision", "trend_selected_post", "trend_step",
    "ai_recommendations", "x_trend_items", "manual_topics",
    # åŸç¨¿å¤‰æ›ã‚¿ãƒ–
    "script_result", "script_result_original", "script_corrections",
    "script_factcheck", "scr_revision", "scr_selected_post",
    # ç”»åƒã‚³ãƒ¡ãƒ³ãƒˆã‚¿ãƒ–
    "image_result", "image_result_original", "image_corrections",
    "image_factcheck", "img_revision", "img_selected_post",
]


def _autosave():
    """é‡è¦ãªã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«è‡ªå‹•ä¿å­˜"""
    data = {}
    for key in _AUTOSAVE_KEYS:
        val = st.session_state.get(key)
        if val is not None:
            data[key] = val
    if data:
        try:
            AUTOSAVE_PATH.write_text(json.dumps(data, ensure_ascii=False, default=str), encoding="utf-8")
        except Exception:
            pass


def _load_autosave():
    """è‡ªå‹•ä¿å­˜ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰"""
    try:
        if AUTOSAVE_PATH.exists():
            raw = AUTOSAVE_PATH.read_text(encoding="utf-8")
            return json.loads(raw)
    except Exception:
        pass
    return None


def _restore_autosave():
    """è‡ªå‹•ä¿å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«å¾©å…ƒ"""
    data = _load_autosave()
    if not data:
        return False
    for key, val in data.items():
        if key in _AUTOSAVE_KEYS:
            st.session_state[key] = val
    return True


def _clear_autosave():
    """è‡ªå‹•ä¿å­˜ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤"""
    try:
        if AUTOSAVE_PATH.exists():
            AUTOSAVE_PATH.unlink()
    except Exception:
        pass

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒšãƒ¼ã‚¸è¨­å®š
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="ã™ã‚ã—ç¤¾é•· Xãƒã‚¹ãƒˆä½œæˆãƒ„ãƒ¼ãƒ«",
    page_icon="ğŸ¦",
    layout="wide",
    initial_sidebar_state="expanded",
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ã‚«ã‚¹ã‚¿ãƒ CSS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("""
<style>
@import url('https://fonts.googleapis.com/css2?family=Noto+Sans+JP:wght@300;400;500;700;900&display=swap');

.stApp { font-family: 'Noto Sans JP', sans-serif; }

.main-header {
    background: linear-gradient(135deg, #0f0c29 0%, #302b63 50%, #24243e 100%);
    padding: 2rem 2.5rem;
    border-radius: 16px;
    margin-bottom: 2rem;
    box-shadow: 0 8px 32px rgba(0,0,0,0.3);
    position: relative; overflow: hidden;
}
.main-header::before {
    content: ''; position: absolute; top: -50%; right: -20%;
    width: 300px; height: 300px;
    background: radial-gradient(circle, rgba(29,161,242,0.15) 0%, transparent 70%);
    border-radius: 50%;
}
.main-header h1 { color: #fff; font-size: 1.8rem; font-weight: 700; margin: 0; position: relative; }
.main-header p { color: rgba(255,255,255,0.7); font-size: 0.95rem; margin: 0.5rem 0 0 0; position: relative; }

.trend-card {
    background: linear-gradient(145deg, #1a1a2e, #16213e);
    border: 1px solid rgba(29,161,242,0.15);
    border-radius: 12px; padding: 1.2rem 1.4rem; margin: 0.6rem 0;
    transition: all 0.2s;
}
.trend-card:hover { border-color: rgba(29,161,242,0.4); box-shadow: 0 4px 16px rgba(29,161,242,0.1); }
.trend-title { color: #fff; font-weight: 600; font-size: 0.95rem; margin-bottom: 0.3rem; }
.trend-source { color: rgba(255,255,255,0.4); font-size: 0.78rem; }
.trend-reason { color: #FFA500; font-size: 0.82rem; margin-top: 0.4rem; font-style: italic; }

.post-card {
    background: linear-gradient(145deg, #1a1a2e, #16213e);
    border: 1px solid rgba(29,161,242,0.2);
    border-radius: 16px; padding: 1.8rem; margin: 1.2rem 0;
    box-shadow: 0 4px 20px rgba(0,0,0,0.2);
    transition: transform 0.2s, box-shadow 0.2s;
}
.post-card:hover { transform: translateY(-2px); box-shadow: 0 8px 30px rgba(29,161,242,0.15); }
.post-card-header {
    display: flex; justify-content: space-between; align-items: center;
    margin-bottom: 1rem; padding-bottom: 0.8rem;
    border-bottom: 1px solid rgba(255,255,255,0.08);
}
.post-card-title { color: #1DA1F2; font-weight: 700; font-size: 1.1rem; }
.post-card-score {
    background: linear-gradient(135deg, #1DA1F2, #0d8bd9);
    color: #fff; padding: 0.3rem 0.8rem; border-radius: 20px;
    font-size: 0.85rem; font-weight: 600;
}
.post-card-body {
    color: rgba(255,255,255,0.9); line-height: 1.85;
    font-size: 1rem; white-space: pre-wrap; margin: 1rem 0;
}
.post-card-meta {
    color: rgba(255,255,255,0.5); font-size: 0.82rem;
    margin-top: 1rem; padding-top: 0.8rem;
    border-top: 1px solid rgba(255,255,255,0.06);
}
.emotion-tag {
    display: inline-block; background: rgba(255,165,0,0.15); color: #FFA500;
    padding: 0.2rem 0.7rem; border-radius: 12px; font-size: 0.8rem;
    font-weight: 500; margin-right: 0.5rem;
}
.hook-tag {
    display: inline-block; background: rgba(29,161,242,0.12); color: #1DA1F2;
    padding: 0.2rem 0.7rem; border-radius: 12px; font-size: 0.8rem; font-weight: 500;
}
.char-counter {
    display: inline-block; background: rgba(29,161,242,0.1); color: #1DA1F2;
    padding: 0.2rem 0.6rem; border-radius: 8px; font-size: 0.82rem; font-weight: 500;
}

.step-indicator { display: flex; justify-content: center; gap: 0.5rem; margin: 1.5rem 0; flex-wrap: wrap; }
.step-item {
    display: flex; align-items: center; gap: 0.4rem;
    padding: 0.5rem 1rem; border-radius: 25px;
    font-size: 0.85rem; font-weight: 500;
}
.step-active { background: rgba(29,161,242,0.15); color: #1DA1F2; border: 1px solid rgba(29,161,242,0.3); }
.step-done { background: rgba(76,175,80,0.1); color: #4CAF50; border: 1px solid rgba(76,175,80,0.2); }
.step-pending { background: rgba(255,255,255,0.03); color: rgba(255,255,255,0.3); border: 1px solid rgba(255,255,255,0.06); }
.step-arrow { color: rgba(255,255,255,0.2); font-size: 1.2rem; }

section[data-testid="stSidebar"] { background: linear-gradient(180deg, #0f0c29, #1a1a2e); }
section[data-testid="stSidebar"] .stMarkdown { color: rgba(255,255,255,0.85); }
</style>
""", unsafe_allow_html=True)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def load_system_prompt():
    if SYSTEM_PROMPT_PATH.exists():
        return SYSTEM_PROMPT_PATH.read_text(encoding="utf-8")
    return ""

def save_history(mode, input_data, result):
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    entry = {"timestamp": datetime.now().isoformat(), "mode": mode, "input": input_data, "result": result}
    filepath = HISTORY_DIR / f"{timestamp}_{mode}.json"
    with open(filepath, "w", encoding="utf-8") as f:
        json.dump(entry, f, ensure_ascii=False, indent=2)

def load_history_list():
    files = sorted(HISTORY_DIR.glob("*.json"), reverse=True)
    entries = []
    for f in files:
        try:
            with open(f, "r", encoding="utf-8") as fp:
                data = json.load(fp)
                entries.append(data)
        except Exception:
            pass
    return entries

def get_mode_label(mode):
    return {"trend": "ğŸ“° ãƒˆãƒ¬ãƒ³ãƒ‰èµ·ç‚¹", "script": "ğŸ“ åŸç¨¿å¤‰æ›", "image": "ğŸ–¼ï¸ ç”»åƒã‚³ãƒ¡ãƒ³ãƒˆ"}.get(mode, mode)

def get_char_limit_text(char_type):
    return {"standard": "æ¨™æº–ãƒã‚¹ãƒˆï¼ˆ200ã€œ280æ–‡å­—ï¼‰", "long": "é•·æ–‡ãƒã‚¹ãƒˆï¼ˆ400ã€œ600æ–‡å­—ï¼‰", "data": "ãƒ‡ãƒ¼ã‚¿ä»˜ããƒã‚¹ãƒˆï¼ˆ100ã€œ200æ–‡å­—ï¼‰"}.get(char_type, "")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Xãƒˆãƒ¬ãƒ³ãƒ‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥èª­ã¿è¾¼ã¿ï¼ˆã‚¯ãƒ©ã‚¦ãƒ‰/åŒæœŸç”¨ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

GITHUB_REPO = "Kota-kun777/x-post-tool"
GITHUB_API_BASE = f"https://api.github.com/repos/{GITHUB_REPO}/contents"


def _get_github_token():
    """GitHub Personal Access Token ã‚’å–å¾—"""
    token = os.environ.get("GITHUB_TOKEN", "")
    if not token:
        try:
            token = st.secrets.get("GITHUB_TOKEN", "")
        except Exception:
            token = ""
    return token


@st.cache_data(ttl=600, show_spinner=False)
def _fetch_trends_from_github():
    """GitHubãƒªãƒã‚¸ãƒˆãƒªã‹ã‚‰Xãƒˆãƒ¬ãƒ³ãƒ‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’APIçµŒç”±ã§å–å¾—ï¼ˆãƒªãƒ‡ãƒ—ãƒ­ã‚¤ä¸è¦ï¼‰

    Returns:
        dict: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ï¼ˆæˆåŠŸæ™‚ï¼‰
        None: å–å¾—å¤±æ•—æ™‚
    """
    GITHUB_API_URL = f"{GITHUB_API_BASE}/x_trends_cache.json"
    try:
        headers = {
            "Accept": "application/vnd.github.v3.raw",
            "User-Agent": "x-post-tool-streamlit",
        }
        token = _get_github_token()
        if token:
            headers["Authorization"] = f"token {token}"
        req = urllib.request.Request(GITHUB_API_URL, headers=headers)
        with urllib.request.urlopen(req, timeout=10) as resp:
            return json.loads(resp.read().decode("utf-8"))
    except Exception:
        return None


def _trigger_pc_sync():
    """GitHub APIã§ _trigger_sync.json ã‚’ä½œæˆ/æ›´æ–°ã—ã¦PCã«åŒæœŸãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡"""
    token = _get_github_token()
    if not token:
        return False, "GITHUB_TOKEN ãŒæœªè¨­å®šã§ã™ã€‚Streamlit Secrets ã«è¿½åŠ ã—ã¦ãã ã•ã„ã€‚"

    api_url = f"{GITHUB_API_BASE}/_trigger_sync.json"
    headers = {
        "Authorization": f"token {token}",
        "Accept": "application/vnd.github.v3+json",
        "User-Agent": "x-post-tool-streamlit",
    }

    # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã®SHAã‚’å–å¾—ï¼ˆæ›´æ–°æ™‚ã«å¿…è¦ï¼‰
    sha = None
    try:
        req = urllib.request.Request(api_url, headers=headers)
        with urllib.request.urlopen(req, timeout=10) as resp:
            data = json.loads(resp.read().decode("utf-8"))
            sha = data.get("sha")
    except Exception:
        pass  # ãƒ•ã‚¡ã‚¤ãƒ«ãŒã¾ã å­˜åœ¨ã—ãªã„

    # ãƒˆãƒªã‚¬ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
    from datetime import timezone as _tz
    trigger = {
        "status": "pending",
        "requested_at": datetime.now(_tz.utc).isoformat(),
    }
    content_b64 = base64.b64encode(
        json.dumps(trigger, ensure_ascii=False, indent=2).encode("utf-8")
    ).decode("utf-8")

    body = {
        "message": "trigger: sync request from cloud",
        "content": content_b64,
    }
    if sha:
        body["sha"] = sha

    try:
        req = urllib.request.Request(
            api_url,
            data=json.dumps(body).encode("utf-8"),
            headers={**headers, "Content-Type": "application/json"},
            method="PUT",
        )
        with urllib.request.urlopen(req, timeout=15) as resp:
            if resp.status in (200, 201):
                return True, None
        return False, "GitHub API ã‚¨ãƒ©ãƒ¼"
    except Exception as e:
        return False, f"é€ä¿¡å¤±æ•—: {e}"


@st.cache_data(ttl=30, show_spinner=False)
def _check_trigger_status():
    """_trigger_sync.json ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ç¢ºèª"""
    api_url = f"{GITHUB_API_BASE}/_trigger_sync.json"
    try:
        headers = {
            "Accept": "application/vnd.github.v3.raw",
            "User-Agent": "x-post-tool-streamlit",
        }
        token = _get_github_token()
        if token:
            headers["Authorization"] = f"token {token}"
        req = urllib.request.Request(api_url, headers=headers)
        with urllib.request.urlopen(req, timeout=10) as resp:
            return json.loads(resp.read().decode("utf-8"))
    except Exception:
        return None


def _load_cache_data():
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆGitHub APIå„ªå…ˆ â†’ ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰"""
    # 1. ã‚¯ãƒ©ã‚¦ãƒ‰ç’°å¢ƒ: GitHub API ã‹ã‚‰æœ€æ–°ã‚’å–å¾—
    if _is_cloud_environment():
        cache = _fetch_trends_from_github()
        if cache:
            return cache, "GitHub"

    # 2. ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«
    if X_TRENDS_CACHE.exists():
        try:
            cache = json.loads(X_TRENDS_CACHE.read_text(encoding="utf-8"))
            return cache, "ãƒ­ãƒ¼ã‚«ãƒ«"
        except Exception:
            pass
    return None, None


def load_cached_x_trends(max_age_hours=24):
    """GitHubã§åŒæœŸã•ã‚ŒãŸXãƒˆãƒ¬ãƒ³ãƒ‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’èª­ã¿è¾¼ã‚€

    å„ªå…ˆé †ä½: GitHub APIï¼ˆå¸¸ã«æœ€æ–°ï¼‰ â†’ ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«

    Args:
        max_age_hours: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®æœ‰åŠ¹æœŸé™ï¼ˆæ™‚é–“ï¼‰ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ24æ™‚é–“
    Returns:
        list: ãƒˆãƒ¬ãƒ³ãƒ‰ãƒªã‚¹ãƒˆï¼ˆæœ‰åŠ¹ãªã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒã‚ã‚‹å ´åˆï¼‰
        None: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãªã— or æœŸé™åˆ‡ã‚Œ
    """
    cache, _source = _load_cache_data()
    if cache is None:
        return None
    try:
        updated_at = datetime.fromisoformat(cache["updated_at"])
        # ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³éå¯¾å¿œã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¯JSTã¨ã¿ãªã—ã¦UTCå¤‰æ›
        if updated_at.tzinfo is None:
            from datetime import timedelta
            updated_at = updated_at - timedelta(hours=9)
        now_utc = datetime.now(updated_at.tzinfo) if updated_at.tzinfo else datetime.utcnow()
        age_hours = (now_utc - updated_at).total_seconds() / 3600
        if age_hours > max_age_hours:
            return None
        return cache.get("trends", [])
    except Exception:
        return None


def get_cached_x_trends_info():
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®æƒ…å ±ã‚’å–å¾—ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼è¡¨ç¤ºç”¨ï¼‰"""
    cache, source = _load_cache_data()
    if cache is None:
        return None
    try:
        updated_at = datetime.fromisoformat(cache["updated_at"])
        # ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³éå¯¾å¿œã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¯JSTã¨ã¿ãªã—ã¦UTCå¤‰æ›
        if updated_at.tzinfo is None:
            from datetime import timedelta
            updated_at_utc = updated_at - timedelta(hours=9)
        else:
            updated_at_utc = updated_at
        now_utc = datetime.now(updated_at_utc.tzinfo) if updated_at_utc.tzinfo else datetime.utcnow()
        age_hours = (now_utc - updated_at_utc).total_seconds() / 3600
        # è¡¨ç¤ºã¯JST
        from datetime import timedelta
        display_time = updated_at if updated_at.tzinfo is None else (updated_at_utc + timedelta(hours=9))
        return {
            "updated_at": display_time.strftime("%Y/%m/%d %H:%M"),
            "count": cache.get("count", 0),
            "age_hours": round(age_hours, 1),
            "is_fresh": age_hours <= 24,
            "source": source,
        }
    except Exception:
        return None


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒˆãƒ¬ãƒ³ãƒ‰è‡ªå‹•å–å¾—
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def fetch_yahoo_realtime_supplementary():
    """Yahoo!ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œç´¢ã§è£œè¶³çš„ã«Xã®è©±é¡Œã‚’å–å¾—ï¼ˆè£œåŠ©ã‚½ãƒ¼ã‚¹ï¼‰

    ã™ã‚ã—ç¤¾é•·ã®4æœ¬æŸ±ã«çµã£ãŸå°‘æ•°ã‚«ãƒ†ã‚´ãƒªã§ã€
    Xä¸Šã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãªè©±é¡Œã‚’è£œè¶³çš„ã«å–å¾—ã™ã‚‹
    """
    import html as html_mod

    # å³é¸ã‚«ãƒ†ã‚´ãƒªï¼ˆ4æœ¬æŸ±ã«ç›´çµã™ã‚‹ã‚‚ã®ã®ã¿ï¼‰
    SEARCH_CATEGORIES = [
        ("å††å®‰ ãƒ‰ãƒ« æ—¥çµŒå¹³å‡", "çµŒæ¸ˆ"),
        ("ChatGPT ç”ŸæˆAI", "ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼"),
        ("ãƒˆãƒ©ãƒ³ãƒ— é–¢ç¨", "å›½éš›æƒ…å‹¢"),
        ("è»¢è· å¹´å ãƒªã‚¹ãƒˆãƒ©", "ã‚­ãƒ£ãƒªã‚¢"),
    ]

    all_results = {}

    for query, category in SEARCH_CATEGORIES:
        try:
            url = f"https://search.yahoo.co.jp/realtime/search?p={urllib.parse.quote(query)}&ei=UTF-8"
            req = urllib.request.Request(url, headers={
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
            })
            resp = urllib.request.urlopen(req, timeout=8)
            html = resp.read().decode("utf-8")

            raw_texts = re.findall(r'<p[^>]*>(.{30,300}?)</p>', html)
            post_urls = re.findall(r'href="(https?://(?:x\.com|twitter\.com)/[^/]+/status/\d+)"', html)

            clean = []
            for text in raw_texts:
                t = re.sub(r'<[^>]+>', '', text).strip()
                t = html_mod.unescape(t)
                if (len(t) > 20 and not any(skip in t for skip in
                    ['JavaScript', 'function', 'var ', 'window.', '{', 'class=', 'img src',
                     'pic.x.com', 'pic.twitter.com'])):
                    clean.append(t)

            if clean:
                items = []
                for i, tweet in enumerate(clean[:3]):  # å„ã‚«ãƒ†ã‚´ãƒªæœ€å¤§3ä»¶
                    post_url = post_urls[i] if i < len(post_urls) else f"https://x.com/search?q={urllib.parse.quote(query)}"
                    items.append({"text": tweet, "url": post_url})
                all_results[category] = items

        except Exception:
            continue

    if not all_results:
        return []

    trends = []
    for category, items in all_results.items():
        for item in items:
            tweet = item["text"]
            title = tweet[:60].rstrip("ã€‚ã€ï¼!.,")
            if len(tweet) > 60:
                title += "â€¦"
            trends.append({
                "title": title,
                "source": f"Yahoo!ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ  ({category})",
                "link": item["url"],
                "published": "",
                "origin": "yahoo_rt",
                "category": category,
                "full_text": tweet,
            })

    # é‡è¤‡é™¤å»
    seen = set()
    unique = []
    for t in trends:
        key = t["title"][:30]
        if key not in seen:
            seen.add(key)
            unique.append(t)

    return unique[:12]


def fetch_google_news():
    """Google News RSSã‹ã‚‰ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—"""
    all_items = []

    # ===== Google News Japan ãƒˆãƒƒãƒ— =====
    try:
        feed = feedparser.parse("https://news.google.com/rss?hl=ja&gl=JP&ceid=JP:ja")
        for entry in feed.entries[:10]:
            title = entry.get("title", "")
            source = ""
            if " - " in title:
                parts = title.rsplit(" - ", 1)
                title, source = parts[0], parts[1]
            item = {"title": title.strip(), "source": f"Google News / {source}".strip(),
                    "link": entry.get("link", ""), "published": entry.get("published", ""), "origin": "google"}
            if not any(n["title"] == item["title"] for n in all_items):
                all_items.append(item)
    except Exception:
        pass

    # ===== Google News ãƒ“ã‚¸ãƒã‚¹ =====
    try:
        feed = feedparser.parse("https://news.google.com/rss/topics/CAAqJggKIiBDQkFTRWdvSUwyMHZNRGx6TVdZU0FtcGhHZ0pLVUNnQVAB?hl=ja&gl=JP&ceid=JP:ja")
        for entry in feed.entries[:6]:
            title = entry.get("title", "")
            source = ""
            if " - " in title:
                parts = title.rsplit(" - ", 1)
                title, source = parts[0], parts[1]
            item = {"title": title.strip(), "source": f"Google News ãƒ“ã‚¸ãƒã‚¹ / {source}".strip(),
                    "link": entry.get("link", ""), "published": entry.get("published", ""), "origin": "google_biz"}
            if not any(n["title"] == item["title"] for n in all_items):
                all_items.append(item)
    except Exception:
        pass

    # ===== Google News ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ =====
    try:
        feed = feedparser.parse("https://news.google.com/rss/topics/CAAqJggKIiBDQkFTRWdvSUwyMHZNRGRqTVhZU0FtcGhHZ0pLVUNnQVAB?hl=ja&gl=JP&ceid=JP:ja")
        for entry in feed.entries[:6]:
            title = entry.get("title", "")
            source = ""
            if " - " in title:
                parts = title.rsplit(" - ", 1)
                title, source = parts[0], parts[1]
            item = {"title": title.strip(), "source": f"Google News ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ / {source}".strip(),
                    "link": entry.get("link", ""), "published": entry.get("published", ""), "origin": "google_tech"}
            if not any(n["title"] == item["title"] for n in all_items):
                all_items.append(item)
    except Exception:
        pass

    return all_items


def fetch_related_news(keyword, max_results=5):
    """Google News RSSã‹ã‚‰ç‰¹å®šã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—"""
    try:
        encoded = urllib.parse.quote(keyword)
        url = f"https://news.google.com/rss/search?q={encoded}&hl=ja&gl=JP&ceid=JP:ja"
        feed = feedparser.parse(url)
        articles = []
        for entry in feed.entries[:max_results]:
            title = entry.get("title", "")
            source = ""
            if " - " in title:
                parts = title.rsplit(" - ", 1)
                title, source = parts[0], parts[1]
            articles.append({"title": title, "source": source, "link": entry.get("link", ""), "published": entry.get("published", "")})
        return articles
    except Exception as e:
        return []


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# AIã«ã‚ˆã‚‹ãƒˆãƒ”ãƒƒã‚¯é¸å®š
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def ai_recommend_topics(news_items, api_key):
    """Claudeã«ãƒ‹ãƒ¥ãƒ¼ã‚¹ä¸€è¦§ã‚’æ¸¡ã—ã€ã™ã‚ã—ç¤¾é•·å‘ãã®ãƒˆãƒ”ãƒƒã‚¯ã‚’å³é¸ã—ã¦ã‚‚ã‚‰ã†"""
    client = anthropic.Anthropic(api_key=api_key)

    # ã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—ã‚’æ˜ç¤º
    tagged_items = []
    for i, n in enumerate(news_items):
        origin = n.get('origin', '')
        if origin == 'x_news':
            tag = '[X]'
        elif origin == 'yahoo_rt':
            tag = '[Yahoo]'
        else:
            tag = '[News]'
        tagged_items.append(f"{i+1}. {tag} {n['title']}ï¼ˆ{n['source']}ï¼‰")
    news_list = "\n".join(tagged_items)

    response = client.messages.create(
        model=CLAUDE_MODEL,
        max_tokens=2000,
        system="""ã‚ãªãŸã¯YouTubeã€Œå¤§äººã®å­¦ã³ç›´ã—TVã€ï¼ˆ90ä¸‡äººç™»éŒ²ï¼‰ã®ã™ã‚ã—ç¤¾é•·ã®Xé‹ç”¨ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã§ã™ã€‚
ã™ã‚ã—ç¤¾é•·ã®4ã¤ã®æŸ±ã¯ã€Œå›½éš›æƒ…å‹¢ã€ã€ŒçµŒæ¸ˆã€ã€Œãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ã€ã€Œäººç”Ÿã‚­ãƒ£ãƒªã‚¢è«–ã€ã§ã™ã€‚

ãƒ‹ãƒ¥ãƒ¼ã‚¹ä¸€è¦§ã‹ã‚‰ã€ã™ã‚ã—ç¤¾é•·ãŒXã§å–ã‚Šä¸Šã’ã‚‹ã¹ããƒˆãƒ”ãƒƒã‚¯ã‚’å³é¸ã—ã¦ãã ã•ã„ã€‚

â–  é¸å®šåŸºæº–ï¼ˆã™ã‚ã—ç¤¾é•·ã¨ã®ç›¸æ€§ï¼‰
- çµŒæ¸ˆãƒ»ãŠé‡‘ãƒ»æŠ•è³‡ã«é–¢é€£ã™ã‚‹è©±é¡Œ â†’ â— æœ€é«˜
- AIãƒ»ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ã®ç¤¾ä¼šçš„ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ â†’ â— æœ€é«˜
- å›½éš›æƒ…å‹¢ãŒæ—¥æœ¬ã®ç”Ÿæ´»ã«å½±éŸ¿ã™ã‚‹è©±é¡Œ â†’ â—‹ é«˜ã„
- ç¤¾ä¼šæ§‹é€ ã®å¤‰åŒ–ï¼ˆäººå£ãƒ»é›‡ç”¨ãƒ»æ•™è‚²ï¼‰ â†’ â—‹ é«˜ã„
- ã€Œå¸¸è­˜ã ã¨æ€ã£ã¦ã„ãŸã“ã¨ãŒå®Ÿã¯é•ã†ã€ç³» â†’ â— æœ€é«˜ï¼ˆå¸¸è­˜è»¢è¦†å‹ã®ãƒ•ãƒƒã‚¯ï¼‰
- æ•°å­—ã‚„ãƒ‡ãƒ¼ã‚¿ã§é©šããŒã‚ã‚‹è©±é¡Œ â†’ â— æœ€é«˜ï¼ˆæ•°å­—ã‚·ãƒ§ãƒƒã‚¯å‹ã®ãƒ•ãƒƒã‚¯ï¼‰
- èŠ¸èƒ½ãƒ»ã‚¹ãƒãƒ¼ãƒ„ãƒ»äº‹ä»¶äº‹æ•… â†’ Ã— å¯¾è±¡å¤–

â–  å‡ºåŠ›: JSONé…åˆ—ã§è¿”ã—ã¦ãã ã•ã„
```json
[
  {
    "index": å…ƒã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ç•ªå·,
    "title": "ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¿ã‚¤ãƒˆãƒ«",
    "source_type": "x" ã¾ãŸã¯ "news"ï¼ˆ[X]ãªã‚‰"x"ã€[News]ãªã‚‰"news"ï¼‰,
    "reason": "ã™ã‚ã—ç¤¾é•·ãŒå–ã‚Šä¸Šã’ã‚‹ã¹ãç†ç”±ï¼ˆ1æ–‡ï¼‰",
    "angle": "åˆ‡ã‚Šå£ã®ææ¡ˆï¼ˆä¾‹ï¼šã€â—‹â—‹ã¨â–³â–³ã®é€†èª¬ã‚’çªãã€ã€éå»ã®â–¡â–¡ã¨æ¯”è¼ƒã—ã¦æ§‹é€ å¤‰åŒ–ã‚’ç¤ºã™ã€ï¼‰",
    "pillars": ["çµŒæ¸ˆ", "ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼"],
    "hook_type": "å¸¸è­˜è»¢è¦†å‹",
    "score": 95
  }
]
```
scoreã¯0-100ã§ã€ã™ã‚ã—ç¤¾é•·ã¨ã®ç›¸æ€§åº¦ã€‚80ç‚¹ä»¥ä¸Šã®ã‚‚ã®ã®ã¿é¸å®šï¼ˆæœ€å¤§5ã¤ï¼‰ã€‚""",
        messages=[{"role": "user", "content": f"ä»¥ä¸‹ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ä¸€è¦§ã‹ã‚‰ã€ã™ã‚ã—ç¤¾é•·å‘ãã®ãƒˆãƒ”ãƒƒã‚¯ã‚’å³é¸ã—ã¦ãã ã•ã„ï¼š\n\n{news_list}"}],
    )

    # JSONã‚’æŠ½å‡ºï¼ˆå …ç‰¢ãªãƒ‘ãƒ¼ã‚µãƒ¼ï¼‰
    text = response.content[0].text

    # æ–¹æ³•1: ```json ... ``` ãƒ–ãƒ­ãƒƒã‚¯ã‹ã‚‰æŠ½å‡º
    code_match = re.search(r'```(?:json)?\s*\n?(\[[\s\S]*?\])\s*\n?```', text)
    if code_match:
        try:
            return json.loads(code_match.group(1))
        except json.JSONDecodeError:
            pass

    # æ–¹æ³•2: æœ€ã‚‚é•·ã„ [ ... ] ã‚’è¦‹ã¤ã‘ã‚‹ï¼ˆè²ªæ¬²ãƒãƒƒãƒï¼‰
    bracket_matches = re.findall(r'\[[\s\S]*\]', text)
    for match in sorted(bracket_matches, key=len, reverse=True):
        try:
            result = json.loads(match)
            if isinstance(result, list) and len(result) > 0:
                return result
        except json.JSONDecodeError:
            continue

    # æ–¹æ³•3: è¡Œã”ã¨ã« [ ã§å§‹ã¾ã‚‹è¡Œã‹ã‚‰ ] ã§çµ‚ã‚ã‚‹è¡Œã¾ã§ã‚’æŠ½å‡º
    lines = text.split('\n')
    json_lines = []
    in_json = False
    for line in lines:
        if line.strip().startswith('['):
            in_json = True
            json_lines = []
        if in_json:
            json_lines.append(line)
        if in_json and line.strip().endswith(']'):
            try:
                return json.loads('\n'.join(json_lines))
            except json.JSONDecodeError:
                continue

    return []


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# é«˜å“è³ªãƒã‚¹ãƒˆç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ENHANCED_GENERATION_PROMPT = """

## â–  è¿½åŠ æŒ‡ç¤ºï¼šã“ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§ã®ç”Ÿæˆå“è³ªã‚’æœ€å¤§åŒ–ã™ã‚‹

### ã™ã‚ã—ç¤¾é•·ã®ãƒˆãƒ¼ãƒ³ï¼ˆæœ€é‡è¦ï¼‰

ã™ã‚ã—ç¤¾é•·ã¯**ã€Œã‚ã‹ã‚Šã‚„ã™ãä»•çµ„ã¿ã‚’è§£èª¬ã™ã‚‹çŸ¥çš„ãªå…ˆç”Ÿã€**ã§ã™ã€‚ä»¥ä¸‹ã®ãƒˆãƒ¼ãƒ³ã‚’å¿…ãšå®ˆã£ã¦ãã ã•ã„ï¼š
- ä¸€äººç§°ã¯å¿…ãš**ã€Œç§ã€**ã‚’ä½¿ã†
- åŸºæœ¬ã¯**ã€Œã§ã™ã€ã€Œã¾ã™ã€ã®ä¸å¯§èª**ã‚’ãƒ™ãƒ¼ã‚¹ã«æ›¸ãï¼ˆå…¨ä½“ã®7å‰²ï¼‰
- è¦æ‰€ã§**ã€Œã€œãªã‚“ã§ã™ã‚ˆã­ã€ã€Œã€œã ã¨æ€ã„ã¾ã™ã€ã€Œã€œã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€**ã®ã‚ˆã†ãªæŸ”ã‚‰ã‹ã„è¡¨ç¾ã‚’æ··ãœã‚‹ï¼ˆ3å‰²ï¼‰
- ä¸Šã‹ã‚‰ç›®ç·šã§ã¯ãªãã€**ã€Œä¸€ç·’ã«æ•´ç†ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€ã€Œä¸€ç·’ã«è€ƒãˆã¦ã¿ã¾ã›ã‚“ã‹ã€**ã¨ã„ã†å§¿å‹¢
- èª­è€…ã‚’ã€Œæˆæ¥­ã«æ‹›ãã€æ„Ÿè¦šã§ã€**ä»•çµ„ã¿ãƒ»æ§‹é€ ãƒ»ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’é †åºç«‹ã¦ã¦ä¸å¯§ã«è§£èª¬ã™ã‚‹**
- **å«è“„ã®ã‚ã‚‹ä¸€æ–‡**ã‚’è¦æ‰€ã«å…¥ã‚Œã‚‹ï¼ˆä¾‹:ã€Œç¨åˆ¶ã¯ç¤¾ä¼šã®é¡ã ã¨è¨€ã‚ã‚Œã¾ã™ã€ã€Œèª²é¡ŒãŒæ˜ç¢ºã§ã‚ã‚‹ã“ã¨ã¯ã€å®Ÿã¯æœ€å¤§ã®æ­¦å™¨ã§ã™ã€ï¼‰
- å¦å®šçš„ãƒ»æ‚²è¦³çš„ã«ãªã‚Šã™ããšã€æœ€å¾Œã¯**èª­è€…ã«è€ƒãˆã‚‹ä½™åœ°ã‚’æ®‹ã™å•ã„ã‹ã‘**ã§ç· ã‚ã‚‹
- èª­å¾Œæ„Ÿã¯ã€Œãªã‚‹ã»ã©ã€ãã†ã„ã†ä»•çµ„ã¿ã ã£ãŸã®ã‹ã€ã¨ã„ã†**çŸ¥çš„ãªç™ºè¦‹**

### æœ€é‡è¦ï¼šã€Œè§£èª¬å‹ã€ã®æ–‡ç« æ§‹é€ 

ã™ã‚ã—ç¤¾é•·ã®ãƒã‚¹ãƒˆã¯ã€Œæ„è¦‹è¡¨æ˜ã€ã§ã¯ãªãã€Œè§£èª¬â†’ç¤ºå”†ã€ã®æ§‹é€ ãŒæ ¸å¿ƒã§ã™ã€‚
ä»¥ä¸‹ã®5æ®µæ§‹æˆã‚’å¿…ãšå®ˆã£ã¦ãã ã•ã„ï¼š

**â‘  å†’é ­ãƒ•ãƒƒã‚¯: ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã‚’æ­¢ã‚ã‚‹1æ–‡**ï¼ˆ1æ–‡ï¼‰
Xã®ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã§ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã®æ‰‹ã‚’æ­¢ã‚ã•ã›ã‚‹ã€Œè¡æ’ƒã®äº‹å®Ÿã€ã€Œæ„å¤–ãªæ•°å­—ã€ã€Œå¸¸è­˜ã‚’è¦†ã™ä¸€è¨€ã€ã§å§‹ã‚ã‚‹ã€‚
è‰¯ã„ä¾‹: ã€Œå¹´å100å„„å††ã®äººã®ç¨ç‡ã¯ã€å¹´å500ä¸‡å††ã®ã‚µãƒ©ãƒªãƒ¼ãƒãƒ³ã‚ˆã‚Šä½ã„ã€‚ã€
è‰¯ã„ä¾‹: ã€Œå‡ºç”Ÿæ•°70ä¸‡äººã€‚ã§ã‚‚ã€ãã‚ŒãŒæ—¥æœ¬ã®"æ­¦å™¨"ã«ãªã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚ã€
è‰¯ã„ä¾‹: ã€Œãƒãƒ•ã‚§ãƒƒãƒˆã¯è¨€ã„ã¾ã—ãŸã€‚ã€ç§ã®ç§˜æ›¸ã®ã»ã†ãŒç¨ç‡ãŒé«˜ã„ã€ã¨ã€‚ã€
æ‚ªã„ä¾‹: âŒã€Œã€œã‚’æ•´ç†ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€ï¼ˆèˆˆå‘³ã‚’å¼•ã‹ãªã„ï¼‰
æ‚ªã„ä¾‹: âŒã€Œã€œãŒè©±é¡Œã«ãªã£ã¦ã„ã¾ã™ã€ï¼ˆãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ç¹°ã‚Šè¿”ã—ï¼‰
å†’é ­1æ–‡ã§ã€Œãˆã€ã©ã†ã„ã†ã“ã¨ï¼Ÿã€ã¨æ€ã‚ã›ã¦ã‹ã‚‰ã€è§£èª¬ã«å…¥ã‚‹ã“ã¨ã€‚

**â‘¡ å±•é–‹: å…·ä½“çš„ãªæ•°å­—ã§æ¯”è¼ƒ**ï¼ˆ3-5æ–‡ï¼‰
å¯¾æ¯”æ§‹é€ ã§æ•°å­—ã‚’ä¸¦ã¹ã¦ã€Œæ„å¤–ãªäº‹å®Ÿã€ã‚’æµ®ã‹ã³ä¸ŠãŒã‚‰ã›ã‚‹ã€‚
ã€ŒAã¯â—‹ï¼…ãªã®ã«ã€Bã¯â–³ï¼…ã€ã®ã‚ˆã†ãªæ¯”è¼ƒã‚»ãƒƒãƒˆãŒå¿…é ˆã€‚

**â‘¢ æ·±æ˜ã‚Š: ãªãœãã†ãªã‚‹ã®ã‹ã®ãƒ¡ã‚«ãƒ‹ã‚ºãƒ è§£èª¬**ï¼ˆ3-5æ–‡ï¼‰
ã€Œãªãœã“ã‚“ãªã“ã¨ãŒèµ·ãã‚‹ã®ã‹ã€â†’ æ§‹é€ çš„ãªç†ç”±ã‚’ä¸å¯§ã«èª¬æ˜ã™ã‚‹ã€‚
ã“ã“ãŒæœ€ã‚‚é‡è¦ã€‚è¡¨é¢çš„ãªç¾è±¡ã§ã¯ãªãã€èƒŒå¾Œã«ã‚ã‚‹ä»•çµ„ã¿ã‚’è§£ãæ˜ã‹ã™ã€‚

**â‘£ è¦–é‡æ‹¡å¤§: ä»–å›½ãƒ»æ­´å²ã¨ã®æ¯”è¼ƒ**ï¼ˆ2-4æ–‡ï¼‰
åŒã˜å•é¡ŒãŒä»–ã®å›½ã‚„æ­´å²ä¸Šã§ã©ã†æ‰±ã‚ã‚Œã¦ã„ã‚‹ã‹ã‚’ç´¹ä»‹ã—ã€è¦–é‡ã‚’åºƒã’ã‚‹ã€‚
å…·ä½“çš„ãªå›½åãƒ»äººåãƒ»åˆ¶åº¦åã‚’å‡ºã™ã€‚

**â‘¤ ç· ã‚: ç¤ºå”†ã«å¯Œã‚€å•ã„ã‹ã‘**ï¼ˆ1-2æ–‡ï¼‰
ã€Œã ã‹ã‚‰ã“ã†ã™ã¹ãã€ã§ã¯ãªãã€èª­è€…ã«è€ƒãˆã•ã›ã‚‹ä¸€æ–‡ã§çµ‚ã‚ã‚‹ã€‚
å«è“„ã®ã‚ã‚‹è¡¨ç¾ã§ä½™éŸ»ã‚’æ®‹ã™ã€‚

### æœ€é«˜å“è³ªã®ãŠæ‰‹æœ¬ï¼ˆã“ã®æ°´æº–ã‚’ç›®æŒ‡ã™ï¼‰

**ãŠæ‰‹æœ¬A: ç¨åˆ¶ã®è§£èª¬å‹ãƒã‚¹ãƒˆ**
> ç¨åˆ¶ã®ä»•çµ„ã¿ã‚’æ•´ç†ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚çµ¦ä¸æ‰€å¾—ã¯ç´¯é€²èª²ç¨ã§ã€å¹´åãŒä¸ŠãŒã‚‹ã»ã©ç¨ç‡ã‚‚ä¸ŠãŒã‚Šã¾ã™ã€‚æœ€é«˜ç¨ç‡ã¯55ï¼…ï¼ˆæ‰€å¾—ç¨45ï¼…+ä½æ°‘ç¨10ï¼…ï¼‰ã€‚ã¨ã“ã‚ãŒæ ªå¼ãªã©ã®é‡‘èæ‰€å¾—ã¯ã€Œåˆ†é›¢èª²ç¨ã€ã§ã€ã©ã‚Œã ã‘å„²ã‘ã¦ã‚‚ä¸€å¾‹20ï¼…ãªã‚“ã§ã™ã€‚ã¤ã¾ã‚Šå¹´å1000ä¸‡å††ã®ã‚µãƒ©ãƒªãƒ¼ãƒãƒ³ã¯33ï¼…ã®ç¨ç‡ãªã®ã«ã€æ ªã§1å„„å††ç¨¼ã„ã äººã¯20ï¼…ã€‚ã“ã®æ§‹é€ ãŒã€Œ1å„„å††ã®å£ã€ã‚’ç”Ÿã‚“ã§ã„ã‚‹ã‚“ã§ã™ã‚ˆã­ã€‚
> å®Ÿéš›ã®æ•°å­—ã‚’è¦‹ã¦ã¿ã‚‹ã¨ã€å¹´å5000ä¸‡å††ã®äººã¯å®ŸåŠ¹ç¨ç‡ç´„40ï¼…ã€‚ã¨ã“ã‚ãŒå¹´å100å„„å††ã®äººã¯ç´„23ï¼…ã¾ã§ä¸‹ãŒã£ã¦ã„ã¾ã—ãŸã€‚ãªãœã“ã‚“ãªã“ã¨ãŒèµ·ãã‚‹ã®ã‹ã€‚ç­”ãˆã¯ã€ŒãŠé‡‘æŒã¡ã»ã©æ ªã§ç¨¼ãã‹ã‚‰ã€ã§ã™ã€‚å¹´å1000ä¸‡å††ã®äººã¯çµ¦ä¸ãŒä¸­å¿ƒã§ã™ãŒã€å¹´å100å„„å††ã®äººã¯åå…¥ã®å¤§éƒ¨åˆ†ãŒæ ªã®å£²å´ç›Šã‚„é…å½“ã«ãªã‚Šã¾ã™ã€‚
> ã‚¢ãƒ¡ãƒªã‚«ã§ã¯ã“ã‚Œã‚’ã€Œãƒãƒ•ã‚§ãƒƒãƒˆãƒ»ãƒ«ãƒ¼ãƒ«ã€ã¨å‘¼ã‚“ã§å•é¡Œè¦–ã—ã¦ã„ã¾ã™ã€‚æŠ•è³‡ã®ç¥æ§˜ã‚¦ã‚©ãƒ¼ãƒ¬ãƒ³ãƒ»ãƒãƒ•ã‚§ãƒƒãƒˆãŒã€Œç§ã®ç§˜æ›¸ã®ã»ã†ãŒç¨ç‡ãŒé«˜ã„ã®ã¯ãŠã‹ã—ã„ã€ã¨ç™ºè¨€ã—ãŸã“ã¨ã‹ã‚‰å§‹ã¾ã£ãŸè­°è«–ã§ã™ã€‚ã¾ã•ã«ä»Šã®æ—¥æœ¬ã¨åŒã˜æ§‹é€ ãªã‚“ã§ã™ã‚ˆã­ã€‚
> ãŸã ã—ã€æœ¬å½“ã®å•é¡Œã¯ã“ã“ã‹ã‚‰ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚è¶…å¯Œè£•å±¤ã®å¤šãã¯ã‚°ãƒ­ãƒ¼ãƒãƒ«ã«è³‡ç”£ã‚’åˆ†æ•£ã•ã›ã¦ã„ã‚‹ã€‚ã‚·ãƒ³ã‚¬ãƒãƒ¼ãƒ«ã®ç¨ç‡ã¯æœ€é«˜17ï¼…ã€UAEã¯0ï¼…ã§ã™ã€‚æ—¥æœ¬ã®ç«¶äº‰åŠ›ã‚’ä¿ã¡ãªãŒã‚‰æ ¼å·®æ˜¯æ­£ã‚‚ã™ã‚‹ã€ã“ã®ãƒãƒ©ãƒ³ã‚¹ã‚’ã©ã†å–ã‚‹ã‹ã€‚ç¨åˆ¶ã¯ç¤¾ä¼šã®é¡ã ã¨è¨€ã‚ã‚Œã¾ã™ã€‚ç§ãŸã¡ãŒã©ã‚“ãªç¤¾ä¼šã‚’ç›®æŒ‡ã™ã®ã‹ã€ãã®ç­”ãˆãŒã“ã“ã«ç¾ã‚Œã¦ã„ã‚‹ã‚ˆã†ãªæ°—ãŒã—ã¾ã™ã€‚

**ã“ã®ãƒã‚¹ãƒˆãŒæœ€é«˜å“è³ªã§ã‚ã‚‹ç†ç”±:**
1. ã€Œæ•´ç†ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€ã¨è§£èª¬ãƒ¢ãƒ¼ãƒ‰ã§å…¥ã‚‹ â†’ èª­è€…ã‚’æˆæ¥­ã«æ‹›ã
2. ç´¯é€²èª²ç¨55ï¼… vs åˆ†é›¢èª²ç¨20ï¼… â†’ ä»•çµ„ã¿ã‚’å…·ä½“çš„ãªæ•°å­—ã§å¯¾æ¯”
3. ã€Œãªãœã“ã‚“ãªã“ã¨ãŒèµ·ãã‚‹ã®ã‹ã€â†’ ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’ä¸å¯§ã«è§£ãæ˜ã‹ã™
4. ã€Œãƒãƒ•ã‚§ãƒƒãƒˆãƒ»ãƒ«ãƒ¼ãƒ«ã€â†’ ä»–å›½ã®å…·ä½“çš„ãªäº‹ä¾‹ã§è¦–é‡ã‚’åºƒã’ã‚‹
5. ã‚·ãƒ³ã‚¬ãƒãƒ¼ãƒ«17ï¼…ã€UAE 0ï¼… â†’ å›½éš›æ¯”è¼ƒã®æ•°å­—ã§è­°è«–ã‚’ç«‹ä½“çš„ã«ã™ã‚‹
6. ã€Œç¨åˆ¶ã¯ç¤¾ä¼šã®é¡ã€â†’ å«è“„ã®ã‚ã‚‹ä¸€æ–‡ã§ä½™éŸ»ã‚’æ®‹ã™ç· ã‚
7. å…¨ä½“ãŒã€Œãƒ‹ãƒ¥ãƒ¼ã‚¹ã®æ„Ÿæƒ³ã€ã§ã¯ãªãã€Œæ§‹é€ ã®è§£èª¬ã€ã«ãªã£ã¦ã„ã‚‹

**ãŠæ‰‹æœ¬B: å°‘å­åŒ–ã®é€†è»¢ç™ºæƒ³å‹ãƒã‚¹ãƒˆ**
> å‡ºç”Ÿæ•°70ä¸‡äººã€‚ã€Œæ—¥æœ¬ã‚„ã°ã„ã€ã¨ã„ã†å£°ã€ç§ã‚‚ã‚ˆãè€³ã«ã—ã¾ã™ã€‚ã§ã‚‚ã¡ã‚‡ã£ã¨é€†ã®è¦–ç‚¹ã§è¦‹ã¦ã¿ã¦ã»ã—ã„ã‚“ã§ã™ã€‚ã“ã‚Œã‹ã‚‰10å¹´ã§AIãŒæœ¬æ ¼çš„ã«ä»•äº‹ã‚’ä»£æ›¿ã—å§‹ã‚ãŸã¨ãã€äººå£14å„„ã®ä¸­å›½ã‚„ã‚¤ãƒ³ãƒ‰ã§ã¯ä½•ãŒèµ·ãã‚‹ã‹ã€‚å¤§é‡ã®å¤±æ¥­è€…ãŒæº¢ã‚Œã‚‹ãƒªã‚¹ã‚¯ã¨éš£ã‚Šåˆã‚ã›ã«ãªã‚‹ã‚“ã§ã™ã‚ˆã­ã€‚
> ä¸€æ–¹ã§äººå£ãŒæ¸›ã‚Šç¶šã‘ã‚‹æ—¥æœ¬ã¯ã€ã€ŒAIãŒä»•äº‹ã‚’å¥ªã†é€Ÿåº¦ã€ã¨ã€Œäººå£ãŒæ¸›ã‚‹é€Ÿåº¦ã€ãŒã¡ã‚‡ã†ã©å™›ã¿åˆã†å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚çš®è‚‰ãªã“ã¨ã«ã€å°‘å­åŒ–ã¨ã„ã†ã€Œå¼±ç‚¹ã€ãŒã€AIæ™‚ä»£ã«ã¯ã€Œæ§‹é€ çš„ãªå¼·ã¿ã€ã«å¤‰ã‚ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚
> èª²é¡ŒãŒæ˜ç¢ºã§ã‚ã‚‹ã“ã¨ã¯ã€å®Ÿã¯æœ€å¤§ã®æ­¦å™¨ã§ã™ã€‚å°‘å­åŒ–ã‚’æ‚²è¦³ã™ã‚‹ã ã‘ã§ã¯ãªãã€ã€ŒAIå›½å®¶ã«ãªã‚‹ã€ã¨ã„ã†ç™ºæƒ³ã®è»¢æ›ãŒã§ãã‚‹ã‹ã©ã†ã‹ã€‚ãã“ãŒåˆ†ã‹ã‚Œé“ã ã¨æ€ã„ã¾ã™ã€‚

### çµ¶å¯¾ã«ã‚„ã£ã¦ã¯ã„ã‘ãªã„ã“ã¨ï¼ˆNGãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰

- âŒ ã€Œã€œãŒè©±é¡Œã«ãªã£ã¦ã„ã¾ã™ã€ã§å§‹ã‚ã‚‹ï¼ˆãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ã‚ªã‚¦ãƒ è¿”ã—ï¼‰
- âŒ æ„Ÿæƒ³ã‚„æ„è¦‹ã ã‘ã‚’ä¸¦ã¹ã‚‹ï¼ˆã€Œã“ã‚Œã¯å¤§å¤‰ãªã“ã¨ã§ã™ã€ã€Œæ³¨ç›®ã™ã¹ãã§ã™ã€ï¼‰
- âŒ ä»•çµ„ã¿ã®è§£èª¬ãªã—ã«çµè«–ã‚’è¿°ã¹ã‚‹ï¼ˆèª­è€…ãŒã€Œãªãœï¼Ÿã€ã¨æ€ã†ï¼‰
- âŒ æ•°å­—ã‚’1ã¤ã ã‘å‡ºã™ï¼ˆæ¯”è¼ƒå¯¾è±¡ãŒãªã‘ã‚Œã°ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆãŒãªã„ï¼‰
- âŒ ã€Œã€œã™ã¹ãã ã€ã€Œã€œã—ãªã‘ã‚Œã°ãªã‚‰ãªã„ã€ã§ä¸Šã‹ã‚‰ç›®ç·šã§èª¬æ•™ã™ã‚‹
- âŒ æŠ½è±¡çš„ãªè¡¨ç¾ã ã‘ã§å…·ä½“ä¾‹ãŒãªã„ï¼ˆã€ŒçµŒæ¸ˆã«å½±éŸ¿ãŒã‚ã‚‹ã€â†’ ã©ã†å½±éŸ¿ï¼Ÿï¼‰

### ä»Šå›ã®ç”Ÿæˆã§å¿…ãšå®ˆã‚‹ã“ã¨

1. **å†’é ­1æ–‡ã¯ã€Œã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã‚’æ­¢ã‚ã‚‹è¡æ’ƒã®äº‹å®Ÿãƒ»æ•°å­—ãƒ»å•ã„ã€ã§å§‹ã‚ã‚‹**
   ã€Œå¹´å100å„„å††ã®äººã®ç¨ç‡ã¯23ï¼…ã€‚å¹´å500ä¸‡å††ã®äººã‚ˆã‚Šä½ã„ã€‚ã€ã®ã‚ˆã†ãªæ„å¤–æ€§ã‚ã‚‹äº‹å®Ÿã€‚
   ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®è¦ç´„ã‚„ã€Œã€œã—ã¦ã¿ã¾ã—ã‚‡ã†ã€ã‹ã‚‰ã¯çµ¶å¯¾ã«å§‹ã‚ãªã„ã€‚

2. **æ•°å­—ã¯å¿…ãšã€Œæ¯”è¼ƒã‚»ãƒƒãƒˆã€ã§ä½¿ã†**
   ã€ŒA ã¯â—‹ï¼…ã€ã ã‘ã§ãªãã€ŒAã¯â—‹ï¼…ãªã®ã«ã€Bã¯â–³ï¼…ã€ã®å¯¾æ¯”ã§é©šãã‚’ç”Ÿã‚€ã€‚

3. **ã€Œãªãœãã†ãªã‚‹ã®ã‹ã€ã®ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’å¿…ãšè§£èª¬ã™ã‚‹**
   è¡¨é¢çš„ãªäº‹å®Ÿã ã‘ã§ãªãã€èƒŒå¾Œã®æ§‹é€ ãƒ»ä»•çµ„ã¿ã‚’èª­è€…ã«æ•™ãˆã‚‹ã€‚
   ã€Œãªãœã“ã‚“ãªã“ã¨ãŒèµ·ãã‚‹ã®ã‹ã€ã€Œç­”ãˆã¯ã€œã§ã™ã€ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒæœ‰åŠ¹ã€‚

4. **ä»–å›½ã®å…·ä½“çš„äº‹ä¾‹ãƒ»æ­´å²çš„å‰ä¾‹ã‚’å¿…ãš1ã¤ä»¥ä¸Šå…¥ã‚Œã‚‹**
   å›½åãƒ»äººåãƒ»åˆ¶åº¦åã‚’å‡ºã™ã€‚æŠ½è±¡çš„ãªã€Œæµ·å¤–ã§ã¯ã€œã€ã¯NGã€‚

5. **ç· ã‚ã¯ã€Œç¤ºå”†ã€ã§ã‚ã£ã¦ã€Œä¸»å¼µã€ã§ã¯ãªã„**
   ã€Œã€œã ã¨è¨€ã‚ã‚Œã¾ã™ã€ã€Œã€œãªæ°—ãŒã—ã¾ã™ã€ã§ä½™éŸ»ã‚’æ®‹ã™ã€‚
   èª­è€…è‡ªèº«ã«è€ƒãˆã•ã›ã‚‹çµ‚ã‚ã‚Šæ–¹ã«ã™ã‚‹ã€‚

6. **600ã€œ800æ–‡å­—ã‚’å³å®ˆã™ã‚‹**
   çŸ­ã™ãã¦æµ…ããªã‚‰ãšã€é•·ã™ãã¦ãƒ€ãƒ¬ãªã„ã€‚ã“ã®ç¯„å›²ã«åã‚ã‚‹ã€‚

### å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®æ³¨æ„

- ãƒã‚¹ãƒˆæœ¬æ–‡ã«ã¯**ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³è¨˜æ³•ã‚’ä¸€åˆ‡ä½¿ã‚ãªã„ã§ãã ã•ã„**ï¼ˆ**å¤ªå­—**ã€# è¦‹å‡ºã—ã€- ãƒªã‚¹ãƒˆç­‰ã¯ç¦æ­¢ï¼‰
- è£…é£¾ãªã—ã®ãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã§è‡ªç„¶ãªæ–‡ç« ã¨ã—ã¦æ›¸ã„ã¦ãã ã•ã„
- æ”¹è¡Œã¯æ®µè½ã®åŒºåˆ‡ã‚Šã«ã®ã¿ä½¿ã£ã¦ãã ã•ã„ï¼ˆæ–‡ã®é€”ä¸­ã§æ”¹è¡Œã—ãªã„ï¼‰
"""


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒã‚¹ãƒˆè§£æ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def parse_generated_posts(text):
    posts = []
    # ã€æ¡ˆ1ã€‘ã€æ¡ˆ2ã€‘ã€æ¡ˆ3ã€‘ ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    pattern = r'ã€æ¡ˆ(\d+)ã€‘'
    parts = re.split(pattern, text)

    # 1000å­—ç‰ˆ/1500å­—ç‰ˆ ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆäº’æ›æ€§ï¼‰
    alt_pattern = r'ã€(1000å­—ç‰ˆ|1500å­—ç‰ˆ|ã‚·ãƒ§ãƒ¼ãƒˆ|ãƒŸãƒ‰ãƒ«|ãƒ­ãƒ³ã‚°)ã€‘'
    alt_parts = re.split(alt_pattern, text)

    if len(parts) >= 3:
        # ã€æ¡ˆ1ã€‘ã€æ¡ˆ2ã€‘ã€æ¡ˆ3ã€‘ ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        for i in range(1, len(parts), 2):
            number = int(parts[i])
            content = parts[i + 1].strip() if i + 1 < len(parts) else ""
            lines = content.split("\n")
            title_line = lines[0].strip() if lines else ""

            # æœ¬æ–‡æŠ½å‡ºï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¡Œã‚’é™¤å¤–ï¼‰
            body_lines = []
            meta_started = False
            for line in lines:
                s = line.strip()
                if any(s.startswith(p) or s.startswith(f"**{p}") for p in ["æ–‡å­—æ•°", "æŠ•ç¨¿ã‚¿ã‚¤ãƒŸãƒ³ã‚°", "å“è³ªã‚¹ã‚³ã‚¢", "---"]):
                    meta_started = True
                if s.startswith("| ãƒã‚§ãƒƒã‚¯") or s.startswith("|----"):
                    meta_started = True
                if not meta_started and s and s != title_line and not s.startswith("ï¼ˆæƒ³å®šã™ã‚‹"):
                    body_lines.append(line)
            body = "\n".join(body_lines).strip()

            score_match = re.search(r'å“è³ªã‚¹ã‚³ã‚¢[ï¼š:]\s*\*{0,2}(\d+)\s*/\s*100', content)
            score = score_match.group(1) if score_match else ""

            posts.append({
                "number": number, "raw": content, "title": title_line,
                "body": body, "score": score, "emotion": "", "hook": "", "timing": ""
            })
    elif len(alt_parts) >= 3:
        # äº’æ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        label_map = {"1000å­—ç‰ˆ": ("ğŸ“", 1), "1500å­—ç‰ˆ": ("ğŸ“–", 2), "ã‚·ãƒ§ãƒ¼ãƒˆ": ("ğŸ“±", 1), "ãƒŸãƒ‰ãƒ«": ("ğŸ“", 2), "ãƒ­ãƒ³ã‚°": ("ğŸ“–", 3)}
        for i in range(1, len(alt_parts), 2):
            label = alt_parts[i]
            content = alt_parts[i + 1].strip() if i + 1 < len(alt_parts) else ""
            emoji, num = label_map.get(label, ("", i))
            lines = content.split("\n")
            title_line = lines[0].strip() if lines else ""
            body_lines = []
            meta_started = False
            for line in lines:
                s = line.strip()
                if any(s.startswith(p) or s.startswith(f"**{p}") for p in ["æ–‡å­—æ•°", "å“è³ªã‚¹ã‚³ã‚¢", "---"]):
                    meta_started = True
                if not meta_started and s and s != title_line:
                    body_lines.append(line)
            body = "\n".join(body_lines).strip()
            score_match = re.search(r'å“è³ªã‚¹ã‚³ã‚¢[ï¼š:]\s*\*{0,2}(\d+)', content)
            score = score_match.group(1) if score_match else ""
            posts.append({"number": num, "raw": content, "title": f"{emoji} {label}",
                          "body": body, "score": score, "emotion": "", "hook": label, "timing": ""})
    else:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãã®ã¾ã¾è¡¨ç¤º
        posts.append({"number": 1, "raw": text, "title": "", "body": text,
                       "score": "", "emotion": "", "hook": "", "timing": ""})
    return posts


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# XæŠ•ç¨¿
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def post_to_x(text, image_data=None):
    try:
        import tweepy
    except ImportError:
        return {"success": False, "error": "tweepy ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"}
    keys = [st.session_state.get(k, "") for k in ["x_consumer_key", "x_consumer_secret", "x_access_token", "x_access_token_secret"]]
    if not all(keys):
        return {"success": False, "error": "X APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"}
    try:
        client = tweepy.Client(consumer_key=keys[0], consumer_secret=keys[1], access_token=keys[2], access_token_secret=keys[3])
        media_ids = None
        if image_data:
            auth = tweepy.OAuth1UserHandler(keys[0], keys[1], keys[2], keys[3])
            api_v1 = tweepy.API(auth)
            import tempfile
            with tempfile.NamedTemporaryFile(suffix=".png", delete=False) as tmp:
                tmp.write(image_data); tmp_path = tmp.name
            media = api_v1.media_upload(tmp_path); os.unlink(tmp_path)
            media_ids = [media.media_id]
        resp = client.create_tweet(text=text, media_ids=media_ids)
        return {"success": True, "url": f"https://x.com/i/status/{resp.data['id']}"}
    except Exception as e:
        return {"success": False, "error": str(e)}


def generate_with_claude(messages, system_prompt):
    api_key = st.session_state.get("anthropic_api_key", "")
    if not api_key:
        st.error("ğŸ”‘ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ Anthropic API Key ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        st.stop()
    client = anthropic.Anthropic(api_key=api_key)
    with st.spinner("ğŸ¤– ã™ã‚ã—ç¤¾é•·ã‚¹ã‚¿ã‚¤ãƒ«ã®ãƒã‚¹ãƒˆã‚’ç”Ÿæˆä¸­..."):
        response = client.messages.create(model=CLAUDE_MODEL, max_tokens=8192, system=system_prompt, messages=messages)
    return response.content[0].text


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Webæ¤œç´¢ï¼ˆãƒˆãƒ”ãƒƒã‚¯ã®æœ€æ–°æƒ…å ±åé›†ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def search_topic_facts(topic_title, max_results=5):
    """Google News RSSã¨ãƒ•ãƒªãƒ¼ã®æ¤œç´¢APIã§ãƒˆãƒ”ãƒƒã‚¯ã®æœ€æ–°ãƒ•ã‚¡ã‚¯ãƒˆã‚’åé›†"""
    facts = []

    # Google News RSSã§æœ€æ–°è¨˜äº‹ã‚’å–å¾—
    try:
        encoded = urllib.parse.quote(topic_title)
        url = f"https://news.google.com/rss/search?q={encoded}&hl=ja&gl=JP&ceid=JP:ja"
        feed = feedparser.parse(url)
        for entry in feed.entries[:max_results]:
            title = entry.get("title", "")
            source = ""
            if " - " in title:
                parts = title.rsplit(" - ", 1)
                title, source = parts[0], parts[1]
            published = entry.get("published", "")
            facts.append(f"[{source}] {title}ï¼ˆ{published}ï¼‰")
    except Exception:
        pass

    # DuckDuckGo Instant Answer APIï¼ˆè£œè¶³ï¼‰
    try:
        ddg_url = f"https://api.duckduckgo.com/?q={urllib.parse.quote(topic_title)}&format=json&no_html=1&skip_disambig=1"
        req = urllib.request.Request(ddg_url, headers={
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        })
        resp = urllib.request.urlopen(req, timeout=5)
        data = json.loads(resp.read().decode("utf-8"))
        # AbstractTextã‹ã‚‰è¦ç´„ã‚’å–å¾—
        abstract = data.get("AbstractText", "")
        if abstract and len(abstract) > 20:
            facts.append(f"[å‚è€ƒ] {abstract[:200]}")
        # RelatedTopicsã‹ã‚‰ã‚‚å–å¾—
        for rt in data.get("RelatedTopics", [])[:3]:
            text = rt.get("Text", "")
            if text and len(text) > 15:
                facts.append(f"[é–¢é€£] {text[:150]}")
    except Exception:
        pass

    return facts


def search_facts_for_topics(selected_topics, progress=None):
    """é¸æŠã•ã‚ŒãŸãƒˆãƒ”ãƒƒã‚¯ç¾¤ã«å¯¾ã—ã¦æœ€æ–°æƒ…å ±ã‚’æ¤œç´¢"""
    all_facts = {}
    for i, topic in enumerate(selected_topics):
        title = topic if isinstance(topic, str) else topic.get("title", "")
        # ãƒˆãƒ”ãƒƒã‚¯åã‹ã‚‰ãƒã‚¹ãƒˆæ•°ã®æƒ…å ±ã‚’é™¤å»
        clean_title = re.sub(r'\s*\(\d[\d,]*ä»¶ã®ãƒã‚¹ãƒˆ\)', '', title).strip()
        if not clean_title:
            continue
        if progress:
            progress.info(f"ğŸ” æœ€æ–°æƒ…å ±ã‚’æ¤œç´¢ä¸­ [{i+1}/{len(selected_topics)}]: {clean_title[:30]}...")
        facts = search_topic_facts(clean_title)
        if facts:
            all_facts[clean_title] = facts
    return all_facts


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒˆãƒ”ãƒƒã‚¯æ–¹å‘æ€§åˆ†æã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def analyze_topic_angles(topics_context, search_facts_text=""):
    """ãƒˆãƒ”ãƒƒã‚¯ã‚’åˆ†æã—ã€3æ¡ˆãã‚Œãã‚Œã®æœ€é©ãªæ–¹å‘æ€§ã‚’ææ¡ˆã™ã‚‹"""
    api_key = st.session_state.get("anthropic_api_key", "")
    if not api_key:
        return None
    client = anthropic.Anthropic(api_key=api_key)

    user_msg = f"""ä»¥ä¸‹ã®ãƒˆãƒ”ãƒƒã‚¯ã«ã¤ã„ã¦ã€Xãƒã‚¹ãƒˆã‚’3ã¤ã®ç•°ãªã‚‹åˆ‡ã‚Šå£ã§ä½œæˆã—ã¾ã™ã€‚
å„åˆ‡ã‚Šå£ã®æœ€é©ãªã€Œæ–¹å‘æ€§ã€ã‚’å…·ä½“çš„ã«ææ¡ˆã—ã¦ãã ã•ã„ã€‚

â–  ãƒˆãƒ”ãƒƒã‚¯æƒ…å ±:
{topics_context}

â–  å‚è€ƒã¨ãªã‚‹æœ€æ–°æƒ…å ±:
{search_facts_text if search_facts_text else "ï¼ˆãªã—ï¼‰"}

â–  3ã¤ã®åˆ‡ã‚Šå£:
ã€æ¡ˆ1ã€‘ä»•çµ„ã¿ã‚„æ­´å²è§£èª¬å‹ â€” ãƒ†ãƒ¼ãƒã®åŸºæœ¬æ§‹é€ ã‚’æ•´ç†ã—ã¦ã€Œãªãœãã†ãªã‚‹ã®ã‹ã€ã‚’è§£ãæ˜ã‹ã™
ã€æ¡ˆ2ã€‘å›½éš›æ¯”è¼ƒå‹ â€” ä»–å›½ã®äº‹ä¾‹ã¨æ¯”è¼ƒã—ã¦æ—¥æœ¬ã®çŠ¶æ³ã‚’ç«‹ä½“çš„ã«è¦‹ã›ã‚‹
ã€æ¡ˆ3ã€‘é‹­ã„è€ƒå¯Ÿãƒ»ä»Šå¾Œã®ã‚·ãƒŠãƒªã‚ªå‹ â€” ãƒ†ãƒ¼ãƒã®æœ¬è³ªã‚’é‹­ãåˆ†æã—ã€ä»Šå¾Œã®å±•é–‹ã‚·ãƒŠãƒªã‚ªã‚’æç¤ºã™ã‚‹

â–  å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆå¿…ãšã“ã®å½¢å¼ã§ï¼‰:
ã€æ¡ˆ1ã®æ–¹å‘æ€§ã€‘ã“ã®ãƒˆãƒ”ãƒƒã‚¯ã®å ´åˆã€å…·ä½“çš„ã«ã©ã®ä»•çµ„ã¿ãƒ»æ­´å²ã‚’è»¸ã«è§£èª¬ã™ã¹ãã‹ï¼ˆ1-2æ–‡ï¼‰
ã€æ¡ˆ2ã®æ–¹å‘æ€§ã€‘ã©ã®å›½ã¨ã®æ¯”è¼ƒãŒæœ€ã‚‚åŠ¹æœçš„ã‹ã€ä½•ã‚’æ¯”è¼ƒè»¸ã«ã™ã¹ãã‹ï¼ˆ1-2æ–‡ï¼‰
ã€æ¡ˆ3ã®æ–¹å‘æ€§ã€‘ã©ã®å´é¢ã‚’é‹­ãè€ƒå¯Ÿã—ã€ã©ã‚“ãªã‚·ãƒŠãƒªã‚ªã‚’æãã¹ãã‹ï¼ˆ1-2æ–‡ï¼‰

å„æ–¹å‘æ€§ã¯å…·ä½“çš„ã«ï¼ˆã€Œç¨åˆ¶ãªã‚‰æ‰€å¾—ç¨ vs é‡‘èæ‰€å¾—èª²ç¨ã®æ§‹é€ ã€ã®ã‚ˆã†ã«ï¼‰æ›¸ã„ã¦ãã ã•ã„ã€‚
æŠ½è±¡çš„ãªææ¡ˆï¼ˆã€Œå¤šè§’çš„ã«åˆ†æã™ã‚‹ã€ç­‰ï¼‰ã¯NGã€‚
"""

    try:
        with st.spinner("ğŸ¯ ãƒˆãƒ”ãƒƒã‚¯ã«æœ€é©ãªåˆ‡ã‚Šå£ã‚’åˆ†æä¸­..."):
            response = client.messages.create(
                model=CLAUDE_MODEL,
                max_tokens=1000,
                system="ã‚ãªãŸã¯Xãƒã‚¹ãƒˆã®ä¼ç”»ãƒ‡ã‚£ãƒ¬ã‚¯ã‚¿ãƒ¼ã§ã™ã€‚ãƒˆãƒ”ãƒƒã‚¯ã®ç‰¹æ€§ã‚’è¦‹æ¥µã‚ã€å„åˆ‡ã‚Šå£ã§æœ€ã‚‚èª­è€…ã®èˆˆå‘³ã‚’å¼•ãå…·ä½“çš„ãªæ–¹å‘æ€§ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚ç°¡æ½”ã«ã€ã—ã‹ã—å…·ä½“çš„ã«ã€‚",
                messages=[{"role": "user", "content": user_msg}],
            )
        return response.content[0].text
    except Exception:
        return None


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

FACTCHECK_SYSTEM_PROMPT = """ã‚ãªãŸã¯äº‹å®Ÿç¢ºèªã®å°‚é–€å®¶ã§ã™ã€‚
Xã«æŠ•ç¨¿ã™ã‚‹ãƒã‚¹ãƒˆåŸç¨¿ã‚’å—ã‘å–ã‚Šã€ä»¥ä¸‹ã®è¦³ç‚¹ã§ãƒã‚§ãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚

â–  ãƒã‚§ãƒƒã‚¯è¦³ç‚¹:
1. äº‹å®Ÿèª¤èª: æ•°å­—ãƒ»äººåãƒ»æ”¿ç­–åãƒ»æ—¥ä»˜ãƒ»æ”¿æ¨©åãªã©ã€æ˜ç¢ºãªäº‹å®Ÿã®èª¤ã‚ŠãŒãªã„ã‹
2. æ™‚åˆ¶ã®èª¤ã‚Š: éå»ã®å‡ºæ¥äº‹ã‚’ç¾åœ¨å½¢ã§æ›¸ã„ã¦ã„ãªã„ã‹ã€ç¾åœ¨ã®çŠ¶æ³ã‚’éå»å½¢ã§æ›¸ã„ã¦ã„ãªã„ã‹
3. ãƒŸã‚¹ãƒªãƒ¼ãƒ‰: æ­£ç¢ºã ãŒæ–‡è„ˆã‚’çœç•¥ã™ã‚‹ã“ã¨ã§èª¤è§£ã‚’ç”Ÿã‚€è¡¨ç¾ãŒãªã„ã‹
4. åã‚Šãƒ»ãƒã‚¤ã‚¢ã‚¹: ä¸€æ–¹çš„ãªè¦‹æ–¹ã«ãªã£ã¦ã„ãªã„ã‹

â–  å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ:
ã¾ãšå…¨ä½“ã®åˆ¤å®šã‚’å‡ºã—ã¦ãã ã•ã„:
âœ… å•é¡Œãªã— / âš ï¸ è¦ç¢ºèªã‚ã‚Š / âŒ èª¤ã‚Šã‚ã‚Š

ãã®å¾Œã€å…·ä½“çš„ãªæŒ‡æ‘˜ãŒã‚ã‚Œã°ä»¥ä¸‹ã®å½¢å¼ã§:
---
ã€æŒ‡æ‘˜1ã€‘
- è©²å½“ç®‡æ‰€: ã€ŒåŸç¨¿ä¸­ã®è©²å½“ãƒ†ã‚­ã‚¹ãƒˆã€
- å•é¡Œ: å…·ä½“çš„ã«ä½•ãŒå•é¡Œã‹
- æ­£ã—ã„æƒ…å ±: æ¤œç´¢çµæœã«åŸºã¥ãæ­£ç¢ºãªæƒ…å ±
- ä¿®æ­£æ¡ˆ: ã“ã†æ›¸ãæ›ãˆã‚‹ã¹ã

ã€æŒ‡æ‘˜2ã€‘
...
---
æŒ‡æ‘˜ãŒãªã‘ã‚Œã°ã€Œå…·ä½“çš„ãªæŒ‡æ‘˜äº‹é …ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ã€ã¨æ›¸ã„ã¦ãã ã•ã„ã€‚

â–  é‡è¦ãƒ«ãƒ¼ãƒ«:
- ã€Œæä¾›ã•ã‚ŒãŸæ¤œç´¢çµæœã€ã«ã‚ã‚‹æƒ…å ±ã‚’æ ¹æ‹ ã«ã™ã‚‹ã“ã¨
- æ ¹æ‹ ãŒãªã„æ¨æ¸¬ã¯é¿ã‘ã€åˆ¤æ–­ã§ããªã„å ´åˆã¯ã€Œç¢ºèªæ¨å¥¨ã€ã¨æ˜è¨˜ã™ã‚‹ã“ã¨
- æ˜ç¢ºãªèª¤ã‚Šä»¥å¤–ã¯éåº¦ã«æŒ‡æ‘˜ã—ãªã„ã“ã¨ï¼ˆäº›æœ«ãªè¡¨ç¾ã®å¥½ã¿ã¯æŒ‡æ‘˜ã—ãªã„ï¼‰
"""


def run_factcheck(post_body, search_results_text=""):
    """ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å®Ÿè¡Œ"""
    api_key = st.session_state.get("anthropic_api_key", "")
    if not api_key:
        return None
    client = anthropic.Anthropic(api_key=api_key)

    user_msg = f"""ä»¥ä¸‹ã®Xãƒã‚¹ãƒˆåŸç¨¿ã‚’ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚

â–  ãƒã‚¹ãƒˆåŸç¨¿:
{post_body}

â–  æ¤œç´¢ã§å¾—ã‚‰ã‚ŒãŸæœ€æ–°æƒ…å ±ï¼ˆå‚è€ƒã«ã—ã¦ãã ã•ã„ï¼‰:
{search_results_text if search_results_text else "ï¼ˆæ¤œç´¢çµæœãªã— â€” ã‚ãªãŸã®çŸ¥è­˜ã®ã¿ã§åˆ¤æ–­ã—ã¦ãã ã•ã„ï¼‰"}

â–  ç¾åœ¨ã®æ—¥ä»˜: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')}
â€» ç¾åœ¨ã®ã‚¢ãƒ¡ãƒªã‚«å¤§çµ±é ˜ã¯ãƒ‰ãƒŠãƒ«ãƒ‰ãƒ»ãƒˆãƒ©ãƒ³ãƒ—ï¼ˆç¬¬2æœŸã€2025å¹´1æœˆå°±ä»»ï¼‰ã§ã™ã€‚
"""

    with st.spinner("ğŸ” ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ä¸­..."):
        response = client.messages.create(
            model=CLAUDE_MODEL,
            max_tokens=2000,
            system=FACTCHECK_SYSTEM_PROMPT,
            messages=[{"role": "user", "content": user_msg}],
        )
    return response.content[0].text


def _factcheck_has_issues(fc_text):
    """ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯çµæœã«å•é¡ŒãŒã‚ã‚‹ã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
    if not fc_text:
        return False
    return "\u26a0\ufe0f" in fc_text or "\u274c" in fc_text


def auto_correct_post(post_body, factcheck_result, search_results_text=""):
    """ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯çµæœã«åŸºã¥ã„ã¦ãƒã‚¹ãƒˆã‚’è‡ªå‹•ä¿®æ­£ã™ã‚‹"""
    api_key = st.session_state.get("anthropic_api_key", "")
    if not api_key:
        return post_body
    client = anthropic.Anthropic(api_key=api_key)

    user_msg = f"""ä»¥ä¸‹ã®Xãƒã‚¹ãƒˆåŸç¨¿ã«ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ã§å•é¡ŒãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚
ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯çµæœã®æŒ‡æ‘˜ã«åŸºã¥ã„ã¦ã€ä¿®æ­£ç‰ˆã®ãƒã‚¹ãƒˆã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

â–  å…ƒã®ãƒã‚¹ãƒˆåŸç¨¿:
{post_body}

â–  ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯çµæœ:
{factcheck_result}

â–  å‚è€ƒæƒ…å ±ï¼ˆæ¤œç´¢çµæœï¼‰:
{search_results_text if search_results_text else "ï¼ˆãªã—ï¼‰"}

â–  ä¿®æ­£ãƒ«ãƒ¼ãƒ«:
- ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ã§æŒ‡æ‘˜ã•ã‚ŒãŸç®‡æ‰€ã®ã¿ã‚’ä¿®æ­£ã™ã‚‹
- ä¿®æ­£ãŒå¿…è¦ãªã„ç®‡æ‰€ã¯å…ƒã®æ–‡ç« ã‚’ãã®ã¾ã¾ç¶­æŒã™ã‚‹
- ã™ã‚ã—ç¤¾é•·ã®ãƒˆãƒ¼ãƒ³ãƒ»æ–‡ä½“ã¯çµ¶å¯¾ã«å¤‰ãˆãªã„
- ä¿®æ­£å¾Œã‚‚600ã€œ800æ–‡å­—ã®ç¯„å›²ã‚’ç¶­æŒã™ã‚‹
- ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³è¨˜æ³•ã¯ä½¿ã‚ãªã„ï¼ˆå¤ªå­—ã€è¦‹å‡ºã—ã€ãƒªã‚¹ãƒˆç­‰ã¯ç¦æ­¢ï¼‰
- ä¿®æ­£å¾Œã®ãƒã‚¹ãƒˆæœ¬æ–‡ã®ã¿ã‚’å‡ºåŠ›ã™ã‚‹ï¼ˆèª¬æ˜ã‚„ã‚³ãƒ¡ãƒ³ãƒˆã¯ä¸è¦ï¼‰
"""

    system_prompt = load_system_prompt() + ENHANCED_GENERATION_PROMPT + """

## è¿½åŠ æŒ‡ç¤º: ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ä¿®æ­£ãƒ¢ãƒ¼ãƒ‰
ã‚ãªãŸã¯ä»Šã€ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ã§æŒ‡æ‘˜ã•ã‚ŒãŸå•é¡Œã‚’ä¿®æ­£ã—ã¦ã„ã¾ã™ã€‚
å…ƒã®ãƒã‚¹ãƒˆã®è‰¯ã„éƒ¨åˆ†ï¼ˆæ§‹é€ ã€ãƒˆãƒ¼ãƒ³ã€ãƒ•ãƒƒã‚¯ï¼‰ã¯ç¶­æŒã—ã¤ã¤ã€äº‹å®Ÿèª¤èªã®ã¿ã‚’æœ€å°é™ã«ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚
"""

    try:
        response = client.messages.create(
            model=CLAUDE_MODEL,
            max_tokens=2000,
            system=system_prompt,
            messages=[{"role": "user", "content": user_msg}],
        )
        return response.content[0].text.strip()
    except Exception:
        return post_body  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# å›³è§£ï¼ˆã‚¤ãƒ³ãƒ•ã‚©ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯ï¼‰ç”Ÿæˆ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

CHARACTER_IMG_PATH = APP_DIR / "character_ref.png"

INFOGRAPHIC_PROMPT = """ã“ã®ç”»åƒã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚’ä½¿ã£ã¦ã€ä»¥ä¸‹ã®ãƒã‚¹ãƒˆå†…å®¹ã®ã€Œæµã‚Œã€ã¨ã€Œæ§‹é€ ã€ãŒã²ã¨ç›®ã§ã‚ã‹ã‚‹å›³è§£ç”»åƒã‚’1æšç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

â–  ãƒã‚¹ãƒˆå†…å®¹ï¼ˆæ ¸å¿ƒã¨ãªã‚‹è¦ç‚¹ã‚’3ã¤ä»¥å†…ã«çµã£ã¦å›³è§£ã™ã‚‹ã“ã¨ï¼‰:
{post_body}

â–  ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®ä½¿ã„æ–¹:
- æ·»ä»˜ç”»åƒã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚’ãã®ã¾ã¾ã®ãƒ‡ã‚¶ã‚¤ãƒ³ã§é…ç½®ã™ã‚‹
- ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãŒå›³ã®æ¨ªã§æŒ‡ã•ã—ãŸã‚Šã€å¹ãå‡ºã—ã§ä¸€è¨€ã‚³ãƒ¡ãƒ³ãƒˆã™ã‚‹ãƒãƒ¼ã‚ºã«ã™ã‚‹
- ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®ãƒ‡ã‚¶ã‚¤ãƒ³ã¯å¤‰ãˆãªã„ã“ã¨ï¼ˆæœè£…ãƒ»é¡”ãƒ»è‰²ã™ã¹ã¦ãã®ã¾ã¾ï¼‰
- å›³è§£ã®ä¸»å½¹ã¯ã€Œæµã‚Œãƒ»æ§‹é€ ã€ã§ã‚ã‚Šã€ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¯æ¡ˆå†…å½¹

â–  èƒŒæ™¯ã®åœ°å›³æ¼”å‡ºï¼ˆå¤§äººã®å­¦ã³ç›´ã—TVé¢¨ï¼‰:
- ã€é‡è¦ã€‘èƒŒæ™¯ã«ãƒˆãƒ”ãƒƒã‚¯ã«åˆã£ãŸåœ°å›³ã‚’ã†ã£ã™ã‚‰ã¨é…ç½®ã—ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹è§£èª¬ç•ªçµ„ã®ã‚ˆã†ãªè‡¨å ´æ„Ÿã‚’å‡ºã™
- å›½éš›æ¯”è¼ƒãƒ»æµ·å¤–ã®è©±é¡Œãƒ»ç‚ºæ›¿ãƒ»è²¿æ˜“ãƒ»åœ°æ”¿å­¦ â†’ ä¸–ç•Œåœ°å›³ã‚’èƒŒæ™¯ã«
- æ—¥æœ¬å›½å†…ã®æ”¿ç­–ãƒ»çµŒæ¸ˆãƒ»ç¤¾ä¼šå•é¡Œ â†’ æ—¥æœ¬åœ°å›³ã‚’èƒŒæ™¯ã«
- ç‰¹å®šã®å›½ã‚„åœ°åŸŸã®è©±é¡Œ â†’ ãã®å›½ãƒ»åœ°åŸŸã®åœ°å›³ã‚’èƒŒæ™¯ã«
- ä¼æ¥­ãƒ»ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ãƒ»æŠ½è±¡çš„ãªä»•çµ„ã¿ã®è©± â†’ åœ°å›³ãªã—ï¼ˆå¾“æ¥ã®ã‚·ãƒ³ãƒ—ãƒ«èƒŒæ™¯ï¼‰
- åœ°å›³ã¯è–„ã„ãƒã‚¤ãƒ“ãƒ¼ã€œã‚°ãƒ¬ãƒ¼ã®åŠé€æ˜ã§ã€å‰é¢ã®å›³è§£ã‚’é‚ªé­”ã—ãªã„ã“ã¨
- è©±é¡Œã«é–¢é€£ã™ã‚‹å›½ãƒ»åœ°åŸŸã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆï¼ˆæ˜ã‚‹ã„è‰²ã§å¼·èª¿ï¼‰ã™ã‚‹ã¨åŠ¹æœçš„

â–  å›³è§£ã®è¨­è¨ˆãƒ«ãƒ¼ãƒ«:
- ã€æœ€é‡è¦ã€‘æ–‡å­—ã¯æœ€å°é™ã€‚ãƒ©ãƒ™ãƒ«ã¯3ã€œ5æ–‡å­—ä»¥å†…ã€é•·ã„æ–‡ç« ã¯çµ¶å¯¾ã«å…¥ã‚Œãªã„
- ã€æ§‹é€ ã€‘å†…å®¹ã®ç¨®é¡ã«å¿œã˜ã¦æœ€é©ãªå›³è§£ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é¸ã¶:
  - å› æœé–¢ä¿‚ãƒ»ãƒ—ãƒ­ã‚»ã‚¹ â†’ å·¦ã‹ã‚‰å³ã¸ã®çŸ¢å°ãƒ•ãƒ­ãƒ¼ï¼ˆSTEP1â†’STEP2â†’STEP3ï¼‰
  - æ¯”è¼ƒ â†’ Before/After ã‚„ 2åˆ—ã®å¯¾æ¯”ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
  - ä»•çµ„ã¿ãƒ»æ§‹é€  â†’ ä¸­å¿ƒã‹ã‚‰æ”¾å°„çŠ¶ã€ã¾ãŸã¯éšå±¤å›³
  - æ™‚ç³»åˆ— â†’ ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³å½¢å¼
- ã€è¦ç‚¹ã€‘ãƒã‚¹ãƒˆå…¨æ–‡ã‚’å›³ã«ã—ãªã„ã€‚æ ¸å¿ƒã®ã€Œãªãœï¼Ÿã€ã€Œã©ã†ãªã‚‹ï¼Ÿã€ã ã‘ã‚’æŠ½å‡º
- ã€æ•°å­—ã€‘ã‚­ãƒ¼ã¨ãªã‚‹æ•°å­—ã¯è¶…å¤§ããå¤ªãç›®ç«‹ãŸã›ã‚‹
- ã€è¦–è¦šã€‘ã‚¢ã‚¤ã‚³ãƒ³ãƒ»çŸ¢å°ãƒ»å›²ã¿ç·šã§è«–ç†ã®æµã‚Œã‚’è¡¨ç¾ã—ã€æ–‡å­—ã«é ¼ã‚‰ãªã„
- è‰²: ãƒã‚¤ãƒ“ãƒ¼(#1a1a2e)ãƒ™ãƒ¼ã‚¹ã€ã‚¹ã‚«ã‚¤ãƒ–ãƒ«ãƒ¼(#1DA1F2)ã€ã‚¢ã‚¯ã‚»ãƒ³ãƒˆã«ã‚ªãƒ¬ãƒ³ã‚¸(#FFA500)
- æ­£æ–¹å½¢ï¼ˆ1:1ï¼‰ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
- å³ä¸‹ã«å°ã•ãã€Œå¤§äººã®å­¦ã³ç›´ã—TVã€
"""

INFOGRAPHIC_PROMPT_NO_REF = """ä»¥ä¸‹ã®ãƒã‚¹ãƒˆå†…å®¹ã®ã€Œæµã‚Œã€ã¨ã€Œæ§‹é€ ã€ãŒã²ã¨ç›®ã§ã‚ã‹ã‚‹å›³è§£ç”»åƒã‚’1æšç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

â–  ãƒã‚¹ãƒˆå†…å®¹ï¼ˆæ ¸å¿ƒã¨ãªã‚‹è¦ç‚¹ã‚’3ã¤ä»¥å†…ã«çµã£ã¦å›³è§£ã™ã‚‹ã“ã¨ï¼‰:
{post_body}

â–  èƒŒæ™¯ã®åœ°å›³æ¼”å‡ºï¼ˆå¤§äººã®å­¦ã³ç›´ã—TVé¢¨ï¼‰:
- ã€é‡è¦ã€‘èƒŒæ™¯ã«ãƒˆãƒ”ãƒƒã‚¯ã«åˆã£ãŸåœ°å›³ã‚’ã†ã£ã™ã‚‰ã¨é…ç½®ã—ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹è§£èª¬ç•ªçµ„ã®ã‚ˆã†ãªè‡¨å ´æ„Ÿã‚’å‡ºã™
- å›½éš›æ¯”è¼ƒãƒ»æµ·å¤–ã®è©±é¡Œãƒ»ç‚ºæ›¿ãƒ»è²¿æ˜“ãƒ»åœ°æ”¿å­¦ â†’ ä¸–ç•Œåœ°å›³ã‚’èƒŒæ™¯ã«
- æ—¥æœ¬å›½å†…ã®æ”¿ç­–ãƒ»çµŒæ¸ˆãƒ»ç¤¾ä¼šå•é¡Œ â†’ æ—¥æœ¬åœ°å›³ã‚’èƒŒæ™¯ã«
- ç‰¹å®šã®å›½ã‚„åœ°åŸŸã®è©±é¡Œ â†’ ãã®å›½ãƒ»åœ°åŸŸã®åœ°å›³ã‚’èƒŒæ™¯ã«
- ä¼æ¥­ãƒ»ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ãƒ»æŠ½è±¡çš„ãªä»•çµ„ã¿ã®è©± â†’ åœ°å›³ãªã—ï¼ˆå¾“æ¥ã®ã‚·ãƒ³ãƒ—ãƒ«èƒŒæ™¯ï¼‰
- åœ°å›³ã¯è–„ã„ãƒã‚¤ãƒ“ãƒ¼ã€œã‚°ãƒ¬ãƒ¼ã®åŠé€æ˜ã§ã€å‰é¢ã®å›³è§£ã‚’é‚ªé­”ã—ãªã„ã“ã¨
- è©±é¡Œã«é–¢é€£ã™ã‚‹å›½ãƒ»åœ°åŸŸã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆï¼ˆæ˜ã‚‹ã„è‰²ã§å¼·èª¿ï¼‰ã™ã‚‹ã¨åŠ¹æœçš„

â–  å›³è§£ã®è¨­è¨ˆãƒ«ãƒ¼ãƒ«:
- ã€æœ€é‡è¦ã€‘æ–‡å­—ã¯æœ€å°é™ã€‚ãƒ©ãƒ™ãƒ«ã¯3ã€œ5æ–‡å­—ä»¥å†…ã€é•·ã„æ–‡ç« ã¯çµ¶å¯¾ã«å…¥ã‚Œãªã„
- ã€æ§‹é€ ã€‘å†…å®¹ã®ç¨®é¡ã«å¿œã˜ã¦æœ€é©ãªå›³è§£ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é¸ã¶:
  - å› æœé–¢ä¿‚ãƒ»ãƒ—ãƒ­ã‚»ã‚¹ â†’ å·¦ã‹ã‚‰å³ã¸ã®çŸ¢å°ãƒ•ãƒ­ãƒ¼ï¼ˆSTEP1â†’STEP2â†’STEP3ï¼‰
  - æ¯”è¼ƒ â†’ Before/After ã‚„ 2åˆ—ã®å¯¾æ¯”ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
  - ä»•çµ„ã¿ãƒ»æ§‹é€  â†’ ä¸­å¿ƒã‹ã‚‰æ”¾å°„çŠ¶ã€ã¾ãŸã¯éšå±¤å›³
  - æ™‚ç³»åˆ— â†’ ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³å½¢å¼
- ã€è¦ç‚¹ã€‘ãƒã‚¹ãƒˆå…¨æ–‡ã‚’å›³ã«ã—ãªã„ã€‚æ ¸å¿ƒã®ã€Œãªãœï¼Ÿã€ã€Œã©ã†ãªã‚‹ï¼Ÿã€ã ã‘ã‚’æŠ½å‡º
- ã€æ•°å­—ã€‘ã‚­ãƒ¼ã¨ãªã‚‹æ•°å­—ã¯è¶…å¤§ããå¤ªãç›®ç«‹ãŸã›ã‚‹
- ã€è¦–è¦šã€‘ã‚¢ã‚¤ã‚³ãƒ³ãƒ»çŸ¢å°ãƒ»å›²ã¿ç·šã§è«–ç†ã®æµã‚Œã‚’è¡¨ç¾ã—ã€æ–‡å­—ã«é ¼ã‚‰ãªã„
- è‰²: ãƒã‚¤ãƒ“ãƒ¼(#1a1a2e)ãƒ™ãƒ¼ã‚¹ã€ã‚¹ã‚«ã‚¤ãƒ–ãƒ«ãƒ¼(#1DA1F2)ã€ã‚¢ã‚¯ã‚»ãƒ³ãƒˆã«ã‚ªãƒ¬ãƒ³ã‚¸(#FFA500)
- æ­£æ–¹å½¢ï¼ˆ1:1ï¼‰ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
- å³ä¸‹ã«å°ã•ãã€Œå¤§äººã®å­¦ã³ç›´ã—TVã€
"""


def _load_character_image():
    """ä¿å­˜æ¸ˆã¿ã®ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å‚ç…§ç”»åƒã‚’PIL Imageã¨ã—ã¦èª­ã¿è¾¼ã‚€ï¼ˆãƒˆã‚°ãƒ«OFFæ™‚ã¯Noneï¼‰"""
    if not st.session_state.get("use_character", True):
        return None
    if not CHARACTER_IMG_PATH.exists():
        return None
    try:
        from PIL import Image
        return Image.open(str(CHARACTER_IMG_PATH))
    except Exception:
        return None


def generate_infographic(post_body):
    """Geminiç”»åƒç”Ÿæˆã§ãƒã‚¹ãƒˆå†…å®¹ã®å›³è§£ã‚’ç”Ÿæˆï¼ˆã‚­ãƒ£ãƒ©å‚ç…§ç”»åƒä»˜ãï¼‰"""
    google_api_key = st.session_state.get("google_api_key", "")
    if not google_api_key:
        st.error("ğŸ”‘ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ Google API Key ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        return None

    try:
        from google import genai
        from google.genai import types
    except ImportError:
        st.error("âŒ google-genai ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n`pip install google-genai Pillow` ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        return None

    model = st.session_state.get("gemini_model", "gemini-3-pro-image-preview")

    # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å‚ç…§ç”»åƒã‚’èª­ã¿è¾¼ã¿
    char_img = _load_character_image()

    if char_img is not None:
        # å‚ç…§ç”»åƒä»˜ã: [ãƒ†ã‚­ã‚¹ãƒˆ, ç”»åƒ] ã‚’é€ä¿¡ï¼ˆGoogle AI Studio ã¨åŒã˜æ–¹å¼ï¼‰
        prompt = INFOGRAPHIC_PROMPT.format(post_body=post_body[:300])
        contents = [prompt, char_img]
    else:
        # å‚ç…§ç”»åƒãªã—: ãƒ†ã‚­ã‚¹ãƒˆã®ã¿
        prompt = INFOGRAPHIC_PROMPT_NO_REF.format(post_body=post_body[:300])
        contents = [prompt]

    try:
        client = genai.Client(api_key=google_api_key)

        with st.spinner("ğŸ¨ å›³è§£ã‚’ç”Ÿæˆä¸­ï¼ˆ30ç§’ã»ã©ã‹ã‹ã‚Šã¾ã™ï¼‰..."):
            response = client.models.generate_content(
                model=model,
                contents=contents,
                config=types.GenerateContentConfig(
                    response_modalities=["IMAGE"],
                ),
            )

        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ç”»åƒãƒã‚¤ãƒˆã‚’å–å¾—
        parts = []
        try:
            parts = response.candidates[0].content.parts
        except (AttributeError, IndexError):
            parts = getattr(response, "parts", [])

        for part in parts:
            if getattr(part, "inline_data", None) is not None:
                return part.inline_data.data

        st.warning("âš ï¸ ç”»åƒãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚")
        return None

    except Exception as e:
        st.error(f"âŒ å›³è§£ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
        return None


def generate_infographic_with_model(post_body, model_id):
    """Geminiç”»åƒç”Ÿæˆï¼ˆãƒ¢ãƒ‡ãƒ«æŒ‡å®šç‰ˆï¼‰"""
    google_api_key = st.session_state.get("google_api_key", "")
    if not google_api_key:
        st.error("ğŸ”‘ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ Google API Key ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        return None
    try:
        from google import genai
        from google.genai import types
    except ImportError:
        st.error("âŒ google-genai ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return None

    char_img = _load_character_image()
    if char_img is not None:
        prompt = INFOGRAPHIC_PROMPT.format(post_body=post_body[:300])
        contents = [prompt, char_img]
    else:
        prompt = INFOGRAPHIC_PROMPT_NO_REF.format(post_body=post_body[:300])
        contents = [prompt]

    try:
        client = genai.Client(api_key=google_api_key)
        model_short = model_id.split("-")[1] if "-" in model_id else model_id
        with st.spinner(f"ğŸ¨ å›³è§£ã‚’ç”Ÿæˆä¸­ï¼ˆ{model_short}ï¼‰..."):
            response = client.models.generate_content(
                model=model_id,
                contents=contents,
                config=types.GenerateContentConfig(response_modalities=["IMAGE"]),
            )
        parts = []
        try:
            parts = response.candidates[0].content.parts
        except (AttributeError, IndexError):
            parts = getattr(response, "parts", [])
        for part in parts:
            if getattr(part, "inline_data", None) is not None:
                return part.inline_data.data
        st.warning("âš ï¸ ç”»åƒãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚")
        return None
    except Exception as e:
        st.error(f"âŒ å›³è§£ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
        return None


# ãƒ¢ãƒ‡ãƒ«åˆ¥è¡¨ç¤ºç”¨ã®å®šç¾©
_INFOGRAPHIC_MODELS = {
    "gemini-3-pro-image-preview": {"label": "Pro æœ€é«˜å“è³ª", "suffix": "pro"},
    "gemini-3.1-flash-image-preview": {"label": "Flash æœ€æ–°", "suffix": "flash_latest"},
}


def _render_infographic_ui(post, key_suffix):
    """å›³è§£ç”Ÿæˆãƒœã‚¿ãƒ³ã¨ç”»åƒè¡¨ç¤ºã®UIã‚’æç”»ï¼ˆãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒã‚¿ãƒ–ä»˜ãï¼‰"""
    infographic_key = f"infographic_{key_suffix}"
    has_google_key = bool(st.session_state.get("google_api_key"))

    if not has_google_key:
        return  # Google APIã‚­ãƒ¼æœªè¨­å®šæ™‚ã¯ä½•ã‚‚è¡¨ç¤ºã—ãªã„

    # ãƒ¢ãƒ‡ãƒ«ã”ã¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚­ãƒ¼
    model_keys = {mid: f"infographic_{key_suffix}_{info['suffix']}" for mid, info in _INFOGRAPHIC_MODELS.items()}

    # å¾Œæ–¹äº’æ›: æ—§ã‚­ãƒ¼ã‚’ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã‚­ãƒ¼ã«ç§»è¡Œ
    has_any = any(st.session_state.get(mk) for mk in model_keys.values())
    if st.session_state.get(infographic_key) and not has_any:
        cur_model = st.session_state.get("gemini_model", "gemini-3-pro-image-preview")
        if cur_model in model_keys:
            st.session_state[model_keys[cur_model]] = st.session_state[infographic_key]
            has_any = True

    if has_any:
        # ã‚¿ãƒ–ã§å„ãƒ¢ãƒ‡ãƒ«ã®çµæœã‚’è¡¨ç¤ºãƒ»æ¯”è¼ƒ
        tab_labels = [info["label"] for info in _INFOGRAPHIC_MODELS.values()]
        tabs = st.tabs(tab_labels)
        for tab, (model_id, info) in zip(tabs, _INFOGRAPHIC_MODELS.items()):
            mk = model_keys[model_id]
            with tab:
                img_bytes = st.session_state.get(mk)
                if img_bytes:
                    st.image(img_bytes, caption=f"ğŸ“Š {info['label']}", use_container_width=True)
                    col_dl, col_regen = st.columns(2)
                    with col_dl:
                        st.download_button(
                            "ğŸ’¾ DL",
                            data=img_bytes,
                            file_name=f"infographic_{key_suffix}_{info['suffix']}.png",
                            mime="image/png",
                            key=f"dl_img_{key_suffix}_{info['suffix']}",
                            use_container_width=True,
                        )
                    with col_regen:
                        if st.button("ğŸ”„ å†ç”Ÿæˆ", key=f"regen_{key_suffix}_{info['suffix']}", use_container_width=True):
                            img_data = generate_infographic_with_model(post["body"], model_id)
                            if img_data:
                                st.session_state[mk] = img_data
                                st.rerun()
                else:
                    if st.button(f"ğŸ¨ {info['label']}ã§ç”Ÿæˆ", key=f"gen_{key_suffix}_{info['suffix']}", use_container_width=True):
                        img_data = generate_infographic_with_model(post["body"], model_id)
                        if img_data:
                            st.session_state[mk] = img_data
                            st.rerun()
    else:
        # åˆå›: é¸æŠä¸­ã®ãƒ¢ãƒ‡ãƒ«ã§ç”Ÿæˆãƒœã‚¿ãƒ³
        if st.button("ğŸ¨ ã“ã®å†…å®¹ã®å›³è§£ã‚’ç”Ÿæˆ", key=f"gen_img_{key_suffix}", use_container_width=True):
            cur_model = st.session_state.get("gemini_model", "gemini-3-pro-image-preview")
            img_data = generate_infographic(post["body"])
            if img_data:
                if cur_model in model_keys:
                    st.session_state[model_keys[cur_model]] = img_data
                st.session_state[infographic_key] = img_data  # å¾Œæ–¹äº’æ›
                st.rerun()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# çµæœè¡¨ç¤º + å€‹åˆ¥ä¿®æ­£ãƒ•ãƒ­ãƒ¼
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _render_post_card(post, key_prefix="", is_selected=False):
    """ãƒã‚¹ãƒˆã‚«ãƒ¼ãƒ‰ã‚’Streamlitãƒã‚¤ãƒ†ã‚£ãƒ–éƒ¨å“ã§ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°"""
    border = is_selected
    with st.container(border=True):
        # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œ: ã‚¿ã‚¤ãƒˆãƒ« + ã‚¹ã‚³ã‚¢
        score_str = f"ã€€`{post['score']}/100`" if post.get("score") else ""
        st.markdown(f"**ã€æ¡ˆ{post['number']}ã€‘{post['title']}**{score_str}")
        # æœ¬æ–‡
        st.markdown(post["body"])
        # æ–‡å­—æ•°
        st.caption(f"ğŸ“ {len(post['body'])}æ–‡å­—")


def display_generated_results(result_text, key_prefix=""):
    """ç”Ÿæˆçµæœã‚’ç¸¦ãƒ•ãƒ­ãƒ¼ã§è¡¨ç¤º: 3æ¡ˆ â†’ é¸æŠæ¡ˆ â†’ ä¿®æ­£ç‰ˆ"""
    posts = parse_generated_posts(result_text)
    x_ok = all(st.session_state.get(k) for k in ["x_consumer_key", "x_consumer_secret", "x_access_token", "x_access_token_secret"])

    revision_key = f"{key_prefix}_revision"
    selected_key = f"{key_prefix}_selected_post"
    selected_post = st.session_state.get(selected_key)
    has_revision = bool(st.session_state.get(revision_key))

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # STEP 1: 3æ¡ˆã‚’å¸¸ã«è¡¨ç¤º
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    for post in posts:
        is_this_selected = (selected_post and selected_post["number"] == post["number"])
        _render_post_card(post, key_prefix=key_prefix, is_selected=is_this_selected)

        k = f"{key_prefix}_{post['number']}"
        col_select, col_copy, col_post_btn = st.columns(3)
        with col_select:
            if is_this_selected:
                st.button(f"âœ… æ¡ˆ{post['number']}ã‚’é¸æŠä¸­", key=f"sel_{k}",
                          use_container_width=True, disabled=True)
            else:
                if st.button(f"âœï¸ ã“ã®æ¡ˆã‚’é¸ã‚“ã§ä¿®æ­£", key=f"sel_{k}", use_container_width=True):
                    st.session_state[selected_key] = post
                    st.session_state.pop(revision_key, None)
                    st.rerun()
        with col_copy:
            with st.popover("ğŸ“‹ ã‚³ãƒ”ãƒ¼", use_container_width=True):
                st.text_area("ã‚³ãƒ”ãƒ¼ç”¨", value=post["body"], height=300, key=f"cp_{k}")
        with col_post_btn:
            if x_ok:
                with st.popover("ğŸ¦ æŠ•ç¨¿", use_container_width=True):
                    st.warning("âš ï¸ Xã«æŠ•ç¨¿ã—ã¾ã™ã€‚")
                    st.text_area("å†…å®¹", value=post["body"], height=150, key=f"pv_{k}", disabled=True)
                    if st.button("âœ… ç¢ºå®šã—ã¦æŠ•ç¨¿", key=f"cf_{k}", type="primary"):
                        r = post_to_x(post["body"])
                        if r["success"]:
                            st.success(f"âœ… [è¦‹ã‚‹]({r['url']})")
                        else:
                            st.error(f"âŒ {r['error']}")
            else:
                st.caption("ğŸ”’ X APIæœªè¨­å®š")

        # å›³è§£ç”Ÿæˆï¼ˆé¸æŠã•ã‚Œã¦ã„ãªã„æ¡ˆã®ã¿ç›´ä¸‹ã«è¡¨ç¤ºï¼‰
        if not is_this_selected:
            _render_infographic_ui(post, f"{key_prefix}_{post['number']}")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # STEP 2: é¸æŠä¸­ã®æ¡ˆ â†’ ä¿®æ­£æŒ‡ç¤ºå…¥åŠ›
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    if selected_post and not has_revision:
        sel = selected_post
        st.markdown("---")
        st.markdown(f"#### â¬‡ï¸ ã€æ¡ˆ{sel['number']}ã€‘{sel['title']} ã‚’ä¿®æ­£")

        revision_instruction = st.text_area(
            "ä¿®æ­£æŒ‡ç¤ºã‚’å…¥åŠ›",
            height=100,
            placeholder="ä¾‹: ã‚‚ã£ã¨å‰å‘ãã«ã€å†’é ­ã®æ•°å­—ã‚’å¤‰ãˆã¦ã€æœ€å¾Œã«è¡Œå‹•ã‚’ä¿ƒã™ä¸€è¨€ã‚’è¿½åŠ ...",
            key=f"rev_inst_{key_prefix}",
        )
        col_go, col_cancel = st.columns(2)
        with col_go:
            if st.button("ğŸ¤– ä¿®æ­£ç‰ˆã‚’ç”Ÿæˆ", type="primary", use_container_width=True, key=f"go_rev_{key_prefix}"):
                if revision_instruction.strip():
                    _do_revision(sel, revision_instruction, key_prefix)
                else:
                    st.warning("ä¿®æ­£æŒ‡ç¤ºã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        with col_cancel:
            if st.button("âŒ é¸æŠã‚’è§£é™¤", use_container_width=True, key=f"cancel_rev_{key_prefix}"):
                st.session_state.pop(selected_key, None)
                st.rerun()

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # STEP 3: ä¿®æ­£ç‰ˆã‚’ä¸‹ã«è¡¨ç¤º
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    if has_revision:
        revision = st.session_state[revision_key]
        revised_post = revision["post"]

        st.markdown("---")
        st.markdown("#### â¬‡ï¸ âœï¸ ä¿®æ­£ç‰ˆ")
        _render_post_card(revised_post, key_prefix=key_prefix, is_selected=True)

        k = f"{key_prefix}_revised"
        col_copy, col_post, col_clear = st.columns(3)
        with col_copy:
            with st.popover("ğŸ“‹ ã‚³ãƒ”ãƒ¼", use_container_width=True):
                st.text_area("ã‚³ãƒ”ãƒ¼ç”¨", value=revised_post["body"], height=300, key=f"cp_{k}")
        with col_post:
            if x_ok:
                with st.popover("ğŸ¦ æŠ•ç¨¿", use_container_width=True):
                    st.warning("âš ï¸ Xã«æŠ•ç¨¿ã—ã¾ã™ã€‚")
                    st.text_area("å†…å®¹", value=revised_post["body"], height=150, key=f"pv_{k}", disabled=True)
                    if st.button("âœ… ç¢ºå®šã—ã¦æŠ•ç¨¿", key=f"cf_{k}", type="primary"):
                        r = post_to_x(revised_post["body"])
                        if r["success"]:
                            st.success(f"âœ… [è¦‹ã‚‹]({r['url']})")
                        else:
                            st.error(f"âŒ {r['error']}")
            else:
                st.caption("ğŸ”’ X APIæœªè¨­å®š")
        with col_clear:
            if st.button("ğŸ”™ é¸æŠã‚’è§£é™¤", key=f"back_{key_prefix}", use_container_width=True):
                st.session_state.pop(revision_key, None)
                st.session_state.pop(selected_key, None)
                st.rerun()

        # å›³è§£ç”Ÿæˆï¼ˆä¿®æ­£ç‰ˆï¼‰
        _render_infographic_ui(revised_post, f"{key_prefix}_revised")

        # ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯çµæœ
        fc = revision.get("factcheck")
        if fc:
            with st.expander("ğŸ” ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯çµæœ", expanded=False):
                st.markdown(fc)

        # ã•ã‚‰ã«ä¿®æ­£
        st.markdown("---")
        st.markdown("##### ğŸ”„ ã•ã‚‰ã«ä¿®æ­£ã™ã‚‹")
        further_instruction = st.text_area(
            "ä¿®æ­£æŒ‡ç¤º",
            height=80,
            placeholder="ä¾‹: ã‚‚ã†å°‘ã—çŸ­ãã€å†’é ­ã‚’ã‚‚ã£ã¨ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã®ã‚ã‚‹æ•°å­—ã«ã—ã¦...",
            key=f"further_{key_prefix}",
        )
        if st.button("ğŸ”„ ã“ã®æ¡ˆã‚’ã•ã‚‰ã«ä¿®æ­£", type="primary", use_container_width=True, key=f"revise_again_{key_prefix}"):
            if further_instruction.strip():
                _do_revision(revised_post, further_instruction, key_prefix)
            else:
                st.warning("ä¿®æ­£æŒ‡ç¤ºã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

        # ä¿®æ­£å±¥æ­´
        history = revision.get("history", [])
        if history:
            with st.expander(f"ğŸ“œ ä¿®æ­£å±¥æ­´ï¼ˆ{len(history)}å›ï¼‰"):
                for i, h in enumerate(history):
                    st.caption(f"**{i+1}å›ç›®:** {h['instruction']}")

    with st.expander("ğŸ“„ ç”Ÿæˆå…¨æ–‡ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰"):
        st.text(result_text)


def _do_revision(original_post, instruction, key_prefix):
    """é¸æŠã•ã‚ŒãŸæ¡ˆã«å¯¾ã—ã¦ä¿®æ­£ã‚’å®Ÿè¡Œ"""
    system_prompt = load_system_prompt() + ENHANCED_GENERATION_PROMPT

    msg = f"""ä»¥ä¸‹ã®Xãƒã‚¹ãƒˆã‚’ã€ä¿®æ­£æŒ‡ç¤ºã«å¾“ã£ã¦ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚

â–  å…ƒã®ãƒã‚¹ãƒˆï¼ˆæ¡ˆ{original_post['number']}ï¼‰:
{original_post['body']}

â–  ä¿®æ­£æŒ‡ç¤º:
{instruction}

â–  ãƒ«ãƒ¼ãƒ«:
- ä¿®æ­£æŒ‡ç¤ºã«å¿ å®Ÿã«å¾“ã£ã¦ãã ã•ã„
- 1æ–‡ç›®ã¯èª­è€…ã®èˆˆå‘³ã‚’å¼·ãå¼•ãä¸€æ–‡ã«ã™ã‚‹ã“ã¨ï¼ˆæ„å¤–ãªæ•°å­—ã€é€†èª¬çš„ãªå•ã„ã€é©šãã®äº‹å®Ÿãªã©ï¼‰
- 1æ–‡ç›®ã®å¾Œã™ãã«ã€å‰æã¨ãªã‚‹çŸ¥è­˜ã‚„èƒŒæ™¯ã‚’ç°¡æ½”ã«èª¬æ˜ã—ã¦ã‹ã‚‰æœ¬é¡Œã«å…¥ã‚‹ã“ã¨
- ã™ã‚ã—ç¤¾é•·ã®ã€Œè§£èª¬å‹ã€ãƒˆãƒ¼ãƒ³ã‚’ç¶­æŒã—ã¦ãã ã•ã„ï¼ˆèˆˆå‘³ã¥ã‘ â†’ å‰æçŸ¥è­˜ â†’ ä»•çµ„ã¿ã®è§£èª¬ â†’ æ•°å­—ã®æ¯”è¼ƒ â†’ ç¤ºå”†ã§ç· ã‚ï¼‰
- ä¿®æ­£å¾Œã®ãƒã‚¹ãƒˆã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ã‚„æ¡ˆç•ªå·ã¯ä¸è¦ï¼‰
- 600ã€œ800æ–‡å­—ã‚’ç›®å®‰ã«ã—ã¦ãã ã•ã„
- ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³è¨˜æ³•ã¯ä½¿ã‚ãªã„ã§ãã ã•ã„ï¼ˆå¤ªå­—ã€è¦‹å‡ºã—ã€ãƒªã‚¹ãƒˆç­‰ã¯ç¦æ­¢ï¼‰
"""
    result = generate_with_claude(
        messages=[{"role": "user", "content": msg}],
        system_prompt=system_prompt,
    )

    # ä¿®æ­£å¾Œãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    body = result.strip()

    # ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯
    fc_result = run_factcheck(body)

    # ä¿®æ­£å±¥æ­´ã‚’ä¿æŒ
    revision_key = f"{key_prefix}_revision"
    prev = st.session_state.get(revision_key)
    history = prev["history"].copy() if prev else []
    history.append({"instruction": instruction, "before": original_post["body"]})

    revised_post = {
        "number": original_post["number"],
        "title": original_post.get("title", "").replace("ï¼ˆä¿®æ­£ç‰ˆï¼‰", "") + "ï¼ˆä¿®æ­£ç‰ˆï¼‰",
        "body": body,
        "score": "",
        "emotion": "",
        "hook": "",
        "timing": "",
        "raw": body,
    }

    st.session_state[revision_key] = {
        "post": revised_post,
        "history": history,
        "factcheck": fc_result,
    }
    st.session_state.pop(f"{key_prefix}_selected_post", None)
    _autosave()
    st.rerun()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ã‚µã‚¤ãƒ‰ãƒãƒ¼
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

with st.sidebar:
    st.markdown("## ğŸ”‘ APIè¨­å®š")
    if "anthropic_api_key" not in st.session_state:
        # Streamlit Cloud secrets â†’ ç’°å¢ƒå¤‰æ•° ã®é †ã§APIã‚­ãƒ¼ã‚’å–å¾—
        _ak = os.environ.get("ANTHROPIC_API_KEY", "")
        if not _ak:
            try:
                _ak = st.secrets.get("ANTHROPIC_API_KEY", "")
            except Exception:
                _ak = ""
        st.session_state.anthropic_api_key = _ak
    ak = st.text_input("Anthropic API Key", value=st.session_state.anthropic_api_key, type="password")
    st.session_state.anthropic_api_key = ak
    if ak: st.success("âœ… æ¥ç¶šæ¸ˆã¿")
    else: st.warning("âš ï¸ APIã‚­ãƒ¼ã‚’å…¥åŠ›")

    st.markdown("---")
    st.markdown("## ğŸ¨ å›³è§£ç”Ÿæˆ (Gemini)")
    if "google_api_key" not in st.session_state:
        _gk = os.environ.get("GOOGLE_API_KEY", "")
        if not _gk:
            try:
                _gk = st.secrets.get("GOOGLE_API_KEY", "")
            except Exception:
                _gk = ""
        st.session_state.google_api_key = _gk
    gk = st.text_input("Google API Key", value=st.session_state.google_api_key, type="password", key="gak")
    st.session_state.google_api_key = gk
    if gk:
        st.success("âœ… æ¥ç¶šæ¸ˆã¿")
    else:
        st.caption("ğŸ’¡ å›³è§£ç”Ÿæˆã«ã¯Google APIã‚­ãƒ¼ãŒå¿…è¦")
    gemini_model_options = {
        "Pro æœ€é«˜å“è³ª": "gemini-3-pro-image-preview",
        "Flash æœ€æ–°": "gemini-3.1-flash-image-preview",
    }
    gemini_label = st.radio(
        "å›³è§£ãƒ¢ãƒ‡ãƒ«",
        options=list(gemini_model_options.keys()),
        index=0,
        key="gemini_model_select",
        horizontal=True,
    )
    st.session_state.gemini_model = gemini_model_options[gemini_label]

    # ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼å‚ç…§ç”»åƒï¼ˆãƒˆã‚°ãƒ«å¼ï¼‰
    if CHARACTER_IMG_PATH.exists():
        use_char = st.checkbox("ğŸ§‘â€ğŸ’¼ ã™ã‚ã—ç¤¾é•·ã‚­ãƒ£ãƒ©ã‚’å›³è§£ã«ä½¿ã†", value=True, key="use_char_img")
        st.session_state.use_character = use_char
        if use_char:
            st.image(str(CHARACTER_IMG_PATH), width=60)
            with st.expander("ã‚­ãƒ£ãƒ©ç”»åƒã‚’å¤‰æ›´", expanded=False):
                char_upload = st.file_uploader(
                    "æ–°ã—ã„ç”»åƒã«å·®ã—æ›¿ãˆ",
                    type=["png", "jpg", "jpeg", "webp"],
                    key="char_img_replace",
                )
                if char_upload is not None:
                    CHARACTER_IMG_PATH.write_bytes(char_upload.read())
                    st.success("âœ… å·®ã—æ›¿ãˆå®Œäº†")
                    st.rerun()
    else:
        st.session_state.use_character = False
        char_upload = st.file_uploader(
            "ğŸ§‘â€ğŸ’¼ ã™ã‚ã—ç¤¾é•·ã‚­ãƒ£ãƒ©ç”»åƒ",
            type=["png", "jpg", "jpeg", "webp"],
            key="char_img_upload",
        )
        if char_upload is not None:
            CHARACTER_IMG_PATH.write_bytes(char_upload.read())
            st.success("âœ… ã‚­ãƒ£ãƒ©ç”»åƒã‚’ä¿å­˜ã—ã¾ã—ãŸï¼")
            st.rerun()
        st.caption("ğŸ’¡ å›³è§£ã«ã™ã‚ã—ç¤¾é•·ã‚­ãƒ£ãƒ©ã‚’çµ„ã¿è¾¼ã‚ã¾ã™")

    st.markdown("---")
    with st.expander("ğŸ¦ X APIè¨­å®šï¼ˆä»»æ„ï¼‰", expanded=False):
        st.session_state.x_consumer_key = st.text_input("Consumer Key", type="password", key="xck")
        st.session_state.x_consumer_secret = st.text_input("Consumer Secret", type="password", key="xcs")
        st.session_state.x_access_token = st.text_input("Access Token", type="password", key="xat")
        st.session_state.x_access_token_secret = st.text_input("Access Token Secret", type="password", key="xats")

    st.markdown("---")
    st.markdown("## ğŸ” Xãƒˆãƒ¬ãƒ³ãƒ‰å–å¾—")

    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥æƒ…å ±ã‚’è¡¨ç¤ºï¼ˆå…¨ç’°å¢ƒå…±é€šï¼‰
    cache_info = get_cached_x_trends_info()
    if cache_info:
        source_label = f"ï¼ˆ{cache_info.get('source', '')}ï¼‰" if cache_info.get('source') else ""
        if cache_info["is_fresh"]:
            st.success(f"ğŸ“¦ åŒæœŸã‚­ãƒ£ãƒƒã‚·ãƒ¥{source_label}: {cache_info['count']}ä»¶\n\næ›´æ–°: {cache_info['updated_at']}ï¼ˆ{cache_info['age_hours']}æ™‚é–“å‰ï¼‰")
        else:
            st.warning(f"ğŸ“¦ ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœŸé™åˆ‡ã‚Œï¼ˆ{cache_info['age_hours']}æ™‚é–“å‰ï¼‰\n\nWindows PCã§ sync_x_trends.bat ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")

    if _is_cloud_environment():
        if not cache_info:
            st.info("â˜ï¸ ä¸‹ã®ãƒœã‚¿ãƒ³ã§PCã‹ã‚‰Xãƒˆãƒ¬ãƒ³ãƒ‰ã‚’å–å¾—ã§ãã¾ã™")

        # ğŸ–¥ï¸ PCã«ãƒˆãƒ¬ãƒ³ãƒ‰å–å¾—ã‚’ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
        token = _get_github_token()
        if token:
            if st.button("ğŸ–¥ï¸ PCã«ãƒˆãƒ¬ãƒ³ãƒ‰å–å¾—ã‚’ãƒªã‚¯ã‚¨ã‚¹ãƒˆ", key="trigger_pc_sync", use_container_width=True, type="primary"):
                with st.spinner("ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡ä¸­..."):
                    ok, err = _trigger_pc_sync()
                if ok:
                    st.success("âœ… ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡ï¼PCã§è‡ªå‹•å®Ÿè¡Œã•ã‚Œã¾ã™ï¼ˆæ•°åˆ†ä»¥å†…ï¼‰")
                    st.session_state["_trigger_sent"] = True
                else:
                    st.error(f"âŒ {err}")

            # ãƒˆãƒªã‚¬ãƒ¼ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤º
            trigger = _check_trigger_status()
            if trigger:
                if trigger.get("status") == "pending":
                    st.info("â³ PCå®Ÿè¡Œå¾…ã¡... é€ä¿¡æ™‚åˆ»: " + trigger.get("requested_at", "")[:19].replace("T", " "))
                elif trigger.get("status") == "completed":
                    completed = trigger.get("completed_at", "")[:19].replace("T", " ")
                    st.caption(f"âœ… å‰å›PCå®Ÿè¡Œå®Œäº†: {completed}")
        else:
            st.caption("ğŸ’¡ GITHUB_TOKEN ã‚’ Secrets ã«è¿½åŠ ã™ã‚‹ã¨PCé€£æºãŒä½¿ãˆã¾ã™")

        # ğŸ”„ æœ€æ–°å–å¾—ãƒœã‚¿ãƒ³ï¼ˆGitHub APIã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¦å†å–å¾—ï¼‰
        if st.button("ğŸ”„ Xãƒˆãƒ¬ãƒ³ãƒ‰ã‚’æœ€æ–°ã«æ›´æ–°", key="refresh_x_trends", use_container_width=True):
            _fetch_trends_from_github.clear()
            _check_trigger_status.clear()
            st.rerun()
        # ğŸ“ æ‰‹å‹•å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
        with st.expander("ğŸ“ Xãƒˆãƒ¬ãƒ³ãƒ‰ã‚’æ‰‹å‹•å…¥åŠ›", expanded=not bool(cache_info)):
            st.caption("X.comã®ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’ã‚³ãƒ”ãƒ¼ã—ã¦1è¡Œãšã¤è²¼ã‚Šä»˜ã‘")
            manual_trends = st.text_area(
                "ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆ1è¡Œ1ä»¶ï¼‰",
                height=150,
                placeholder="ç¬¬ä¸‰æ¬¡ä¸–ç•Œå¤§æˆ¦\nã‚¤ã‚¹ãƒ©ã‚¨ãƒ«\næƒ‘æ˜Ÿç›´åˆ—\nç¢ºå®šç”³å‘Š\nAIè¦åˆ¶æ³•æ¡ˆ",
                key="manual_x_trends",
            )
            if st.button("ğŸ’¾ Xãƒˆãƒ¬ãƒ³ãƒ‰ã‚’ä¿å­˜", key="save_manual_trends", use_container_width=True):
                if manual_trends.strip():
                    lines = [l.strip() for l in manual_trends.strip().split("\n") if l.strip()]
                    from datetime import timezone as _tz
                    new_trends = []
                    for i, line in enumerate(lines):
                        new_trends.append({
                            "title": line,
                            "post_count": 0,
                            "category": "ãƒˆãƒ¬ãƒ³ãƒ‰",
                            "time_ago": "",
                            "source": "X ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆæ‰‹å‹•ï¼‰",
                            "origin": "x_news",
                        })
                    cache_data = {
                        "updated_at": datetime.now(_tz.utc).isoformat(),
                        "count": len(new_trends),
                        "trends": new_trends,
                    }
                    # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                    X_TRENDS_CACHE.write_text(
                        json.dumps(cache_data, ensure_ascii=False, indent=2),
                        encoding="utf-8",
                    )
                    st.success(f"âœ… {len(new_trends)}ä»¶ã®Xãƒˆãƒ¬ãƒ³ãƒ‰ã‚’ä¿å­˜ã—ã¾ã—ãŸ")
                    _fetch_trends_from_github.clear()
                    st.rerun()
                else:
                    st.warning("ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        st.caption("Google News + Yahoo!ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œç´¢ã¯å¸¸æ™‚åˆ©ç”¨å¯èƒ½")
    else:
        if is_logged_in():
            st.success("âœ… Xã‚»ãƒƒã‚·ãƒ§ãƒ³ä¿å­˜æ¸ˆã¿")
            st.caption("ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¿ãƒ–ã‹ã‚‰ãƒã‚¹ãƒˆæ•°ä»˜ãã§å–å¾—ã—ã¾ã™")
        else:
            if not cache_info:
                st.info("ğŸ’¡ ãƒ–ãƒ©ã‚¦ã‚¶ãŒé–‹ãã®ã§Xã«ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ãã ã•ã„")
        col_login, col_clear = st.columns([3, 1])
        with col_login:
            if st.button("ğŸ”— Xã«ãƒ­ã‚°ã‚¤ãƒ³" if not is_logged_in() else "ğŸ”„ å†ãƒ­ã‚°ã‚¤ãƒ³", key="x_login_btn", use_container_width=True):
                with st.spinner("ãƒ–ãƒ©ã‚¦ã‚¶ã‚’èµ·å‹•ä¸­... Xã«ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ãã ã•ã„"):
                    result = login_to_x()
                if result:
                    st.success("âœ… ãƒ­ã‚°ã‚¤ãƒ³å®Œäº†ï¼ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¿å­˜æ¸ˆã¿")
                    st.rerun()
                else:
                    st.error("âŒ ãƒ­ã‚°ã‚¤ãƒ³ã«å¤±æ•—ã—ã¾ã—ãŸã€‚å†è©¦è¡Œã—ã¦ãã ã•ã„")
        with col_clear:
            if is_logged_in():
                if st.button("ğŸ—‘ï¸", key="x_clear_btn", help="ã‚»ãƒƒã‚·ãƒ§ãƒ³å‰Šé™¤"):
                    clear_session()
                    st.rerun()

    st.markdown("---")
    st.markdown("## ğŸ“ ç”Ÿæˆãƒ¢ãƒ¼ãƒ‰")
    st.caption("åŒã˜ãƒ†ãƒ¼ãƒã§åˆ‡ã‚Šå£ã‚’å¤‰ãˆãŸ3ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç”Ÿæˆ")
    st.markdown("å„600ã€œ800æ–‡å­— Ã— 3æ¡ˆ")

    st.markdown("---")
    st.markdown("## ğŸ“œ å±¥æ­´")
    hist = load_history_list()
    if not hist: st.caption("ã¾ã å±¥æ­´ãªã—")
    else:
        st.caption(f"{len(hist)}ä»¶")
        for i, e in enumerate(hist[:15]):
            ts = datetime.fromisoformat(e["timestamp"])
            inp = e.get("input", {})
            summary = ""
            if isinstance(inp, dict):
                for k in ["selected_topics", "script", "description"]:
                    v = inp.get(k, "")
                    if v:
                        summary = ", ".join(v[:2]) if isinstance(v, list) else str(v)[:25]
                        break
            if st.button(f"{ts.strftime('%m/%d %H:%M')} {get_mode_label(e['mode'])}\n{summary}", key=f"h_{i}", use_container_width=True):
                st.session_state.view_history = e


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒ˜ãƒƒãƒ€ãƒ¼
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

st.markdown("""
<div class="main-header">
    <h1>ğŸ¦ ã™ã‚ã—ç¤¾é•· Xãƒã‚¹ãƒˆä½œæˆãƒ„ãƒ¼ãƒ«</h1>
    <p>ãƒœã‚¿ãƒ³ä¸€ã¤ã§ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’å–å¾— â†’ AIãŒãŠã™ã™ã‚ãƒˆãƒ”ãƒƒã‚¯ã‚’ææ¡ˆ â†’ é«˜å“è³ªãƒã‚¹ãƒˆã‚’è‡ªå‹•ç”Ÿæˆ</p>
</div>
""", unsafe_allow_html=True)

# å±¥æ­´è¡¨ç¤º
if st.session_state.get("view_history"):
    entry = st.session_state.view_history
    ts = datetime.fromisoformat(entry["timestamp"])
    if st.button("â† æˆ»ã‚‹"):
        st.session_state.view_history = None; st.rerun()
    st.markdown(f"**ğŸ“œ {ts.strftime('%Y/%m/%d %H:%M')} â€” {get_mode_label(entry['mode'])}**")
    with st.expander("ğŸ“¥ å…¥åŠ›"): st.json(entry.get("input", {}))
    st.markdown(entry.get("result", "")); st.stop()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# è‡ªå‹•ä¿å­˜ã‹ã‚‰ã®å¾©å…ƒãƒã‚§ãƒƒã‚¯
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_has_any_result = any(st.session_state.get(k) for k in [
    "trend_result", "script_result", "image_result",
])
if not _has_any_result and not st.session_state.get("_autosave_dismissed"):
    _saved = _load_autosave()
    if _saved and any(_saved.get(k) for k in ["trend_result", "script_result", "image_result"]):
        _tabs_with_data = []
        if _saved.get("trend_result"):
            _tabs_with_data.append("ãƒˆãƒ¬ãƒ³ãƒ‰èµ·ç‚¹")
        if _saved.get("script_result"):
            _tabs_with_data.append("åŸç¨¿å¤‰æ›")
        if _saved.get("image_result"):
            _tabs_with_data.append("ç”»åƒã‚³ãƒ¡ãƒ³ãƒˆ")
        st.info(f"ğŸ’¾ å‰å›ã®ä½œæˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã™ï¼ˆ{', '.join(_tabs_with_data)}ï¼‰")
        col_r, col_d = st.columns(2)
        with col_r:
            if st.button("ğŸ”„ å‰å›ã®ç¶šãã‹ã‚‰å¾©å…ƒ", type="primary", use_container_width=True, key="_restore_btn"):
                _restore_autosave()
                st.rerun()
        with col_d:
            if st.button("âœ–ï¸ æ–°è¦ã§å§‹ã‚ã‚‹", use_container_width=True, key="_dismiss_btn"):
                st.session_state["_autosave_dismissed"] = True
                _clear_autosave()
                st.rerun()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒ¡ã‚¤ãƒ³: ã‚¿ãƒ–
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

tab1, tab2, tab3 = st.tabs(["ğŸ“° ãƒˆãƒ¬ãƒ³ãƒ‰èµ·ç‚¹ï¼ˆãƒ¡ã‚¤ãƒ³ï¼‰", "ğŸ“ åŸç¨¿å¤‰æ›", "ğŸ–¼ï¸ ç”»åƒã‚³ãƒ¡ãƒ³ãƒˆ"])

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ã‚¿ãƒ–1: ãƒˆãƒ¬ãƒ³ãƒ‰èµ·ç‚¹
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with tab1:
    step = st.session_state.get("trend_step", 1)
    cls = {1: ["step-active","step-pending","step-pending"],
           2: ["step-done","step-active","step-pending"],
           3: ["step-done","step-done","step-active"]}
    c = cls.get(step, cls[1])
    st.markdown(f"""
<div class="step-indicator">
    <span class="step-item {c[0]}">â‘  ãƒˆãƒ¬ãƒ³ãƒ‰å–å¾— & AIé¸å®š</span>
    <span class="step-arrow">â†’</span>
    <span class="step-item {c[1]}">â‘¡ ãƒˆãƒ”ãƒƒã‚¯ç¢ºèª & é¸æŠ</span>
    <span class="step-arrow">â†’</span>
    <span class="step-item {c[2]}">â‘¢ ãƒã‚¹ãƒˆç”Ÿæˆ</span>
</div>
""", unsafe_allow_html=True)

    st.markdown("---")

    # â”€â”€ STEP 1: è‡ªå‹•å–å¾— â”€â”€
    st.markdown("### â‘  ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—")
    st.caption("ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã ã‘ã§ã€ä»Šã®ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’è‡ªå‹•å–å¾—ã—ã€ã™ã‚ã—ç¤¾é•·å‘ãã®ãƒˆãƒ”ãƒƒã‚¯ã‚’AIãŒå³é¸ã—ã¾ã™ã€‚")

    col_fetch, col_manual = st.columns([2, 1])
    with col_fetch:
        fetch_clicked = st.button("ğŸ” ä»Šã®ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’å–å¾—ã—ã¦åˆ†æã™ã‚‹", type="primary", use_container_width=True, key="fetch_btn")
    with col_manual:
        with st.popover("âœï¸ æ‰‹å‹•å…¥åŠ›"):
            manual_input = st.text_area("ãƒˆãƒ”ãƒƒã‚¯ã‚’1è¡Œãšã¤", height=100, placeholder="å°‘å­åŒ–\nAIè¦åˆ¶\nå††å®‰", key="manual_in")
            if st.button("è¿½åŠ ", key="add_manual"):
                if manual_input.strip():
                    manual_topics = [l.strip() for l in manual_input.strip().split("\n") if l.strip()]
                    st.session_state.manual_topics = manual_topics
                    st.rerun()

    if fetch_clicked:
        if not st.session_state.get("anthropic_api_key"):
            st.error("ğŸ”‘ APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„")
        else:
            # å‰å›ã®çµæœã‚’ã‚¯ãƒªã‚¢
            for key in ["ai_recommendations", "x_trend_items", "related_news", "raw_news", "trend_step"]:
                if key in st.session_state:
                    del st.session_state[key]

            # ===== ãƒˆãƒ¬ãƒ³ãƒ‰å–å¾—ï¼ˆå„ªå…ˆåº¦é †ï¼‰ =====
            progress = st.empty()

            # â”€â”€ 1. Xãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆãƒ¡ã‚¤ãƒ³ï¼‰ â”€â”€
            x_news_items = []
            x_login_warning = None

            # ã‚¯ãƒ©ã‚¦ãƒ‰ç’°å¢ƒ: GitHubã§åŒæœŸã•ã‚ŒãŸã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰èª­ã¿è¾¼ã¿
            cached_trends = load_cached_x_trends(max_age_hours=24)
            if cached_trends:
                progress.info("ğŸ“± ã€1/3ã€‘Xãƒˆãƒ¬ãƒ³ãƒ‰ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰èª­ã¿è¾¼ã¿ä¸­...")
                for item in cached_trends:
                    count_str = f" ({item['post_count']:,}ä»¶ã®ãƒã‚¹ãƒˆ)" if item.get('post_count') else ""
                    x_news_items.append({
                        "title": item["title"] + count_str,
                        "source": "X ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆåŒæœŸï¼‰",
                        "link": f"https://x.com/search?q={urllib.parse.quote(item['title'])}",
                        "published": item.get("time_ago", ""),
                        "origin": "x_news",
                        "post_count": item.get("post_count", 0),
                    })
                progress.info(f"âœ… Xãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰: {len(x_news_items)}ä»¶")
            elif is_logged_in():
                # ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒ: Playwrightã§ç›´æ¥å–å¾—
                progress.info("ğŸ“± ã€1/3ã€‘Xã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¿ãƒ–ã‹ã‚‰ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’å–å¾—ä¸­...")
                x_news = fetch_x_news_trends()
                if x_news == "login_required":
                    x_login_warning = "âš ï¸ Xã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒåˆ‡ã‚Œã¦ã„ã¾ã™ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰å†ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ãã ã•ã„"
                elif x_news and isinstance(x_news, list):
                    for item in x_news:
                        count_str = f" ({item['post_count']:,}ä»¶ã®ãƒã‚¹ãƒˆ)" if item['post_count'] else ""
                        x_news_items.append({
                            "title": item["title"] + count_str,
                            "source": "X ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒˆãƒ¬ãƒ³ãƒ‰",
                            "link": f"https://x.com/search?q={urllib.parse.quote(item['title'])}",
                            "published": item.get("time_ago", ""),
                            "origin": "x_news",
                            "post_count": item.get("post_count", 0),
                        })
                    progress.info(f"âœ… Xãƒ‹ãƒ¥ãƒ¼ã‚¹: {len(x_news_items)}ä»¶å–å¾—")
                else:
                    x_login_warning = "âš ï¸ Xãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—å¤±æ•—ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰å†ãƒ­ã‚°ã‚¤ãƒ³ã‚’è©¦ã—ã¦ãã ã•ã„"
            else:
                x_login_warning = "ğŸ’¡ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰Xã«ãƒ­ã‚°ã‚¤ãƒ³ã™ã‚‹ã¨ã€Xãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒˆãƒ¬ãƒ³ãƒ‰ã‚‚å–å¾—ã§ãã¾ã™"

            # â”€â”€ 2. Google Newsï¼ˆä¸–ã®ä¸­ã®ãƒˆãƒ¬ãƒ³ãƒ‰ï¼‰ â”€â”€
            progress.info("ğŸ“° ã€2/3ã€‘Google Newsã‹ã‚‰ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’å–å¾—ä¸­...")
            google_items = fetch_google_news()

            # â”€â”€ 3. Yahoo!ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œç´¢ï¼ˆè£œè¶³ï¼‰ â”€â”€
            progress.info("ğŸ” ã€3/3ã€‘Yahoo!ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œç´¢ã§è£œè¶³æƒ…å ±ã‚’å–å¾—ä¸­...")
            yahoo_items = fetch_yahoo_realtime_supplementary()

            # å–å¾—çŠ¶æ³ã‚’è¡¨ç¤º
            counts = []
            if x_news_items:
                counts.append(f"ğŸ¦ Xãƒ‹ãƒ¥ãƒ¼ã‚¹ {len(x_news_items)}ä»¶")
            if google_items:
                counts.append(f"ğŸ“° Google News {len(google_items)}ä»¶")
            if yahoo_items:
                counts.append(f"ğŸ” Yahoo!è£œè¶³ {len(yahoo_items)}ä»¶")
            progress.info(f"âœ… å–å¾—å®Œäº†: {' + '.join(counts)}" if counts else "âš ï¸ ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")

            if x_login_warning:
                st.warning(x_login_warning)

            # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
            st.session_state.x_trend_items = x_news_items
            st.session_state.yahoo_items = yahoo_items

            all_items = x_news_items + google_items + yahoo_items
            if not all_items:
                st.error("ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            else:
                st.session_state.raw_news = all_items

                # AIã«ã¯Google Newsã®ã¿é€ä¿¡ã—ã¦é¸å®š
                if google_items:
                    progress.info("ğŸ¤– Google Newsã‹ã‚‰ã™ã‚ã—ç¤¾é•·å‘ãã®ãƒˆãƒ”ãƒƒã‚¯ã‚’AIãŒé¸å®šä¸­...")
                    try:
                        recommendations = ai_recommend_topics(google_items, st.session_state.anthropic_api_key)
                    except Exception as e:
                        recommendations = []
                        st.error(f"AIé¸å®šã‚¨ãƒ©ãƒ¼: {str(e)}")
                else:
                    recommendations = []

                if recommendations:
                    st.session_state.ai_recommendations = recommendations
                    # é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚‚å…ˆã«å–å¾—
                    progress.info("ğŸ“° é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’åé›†ä¸­...")
                    related = {}
                    for rec in recommendations:
                        keyword = rec.get("title", "")[:20]
                        articles = fetch_related_news(keyword, max_results=3)
                        related[rec["title"]] = articles
                    st.session_state.related_news = related
                    progress.empty()
                    st.session_state.trend_step = 2
                    st.rerun()
                else:
                    progress.empty()
                    # Xãƒˆãƒ¬ãƒ³ãƒ‰ or Yahooè£œè¶³ãŒã‚ã‚Œã°ãã‚Œã ã‘ã§è¡¨ç¤º
                    if x_news_items or yahoo_items:
                        st.session_state.trend_step = 2
                        st.session_state.related_news = {}
                        st.rerun()
                    else:
                        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: AIé¸å®šãŒå¤±æ•—ã—ã¦ã‚‚ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º
                        st.warning("âš ï¸ AIé¸å®šãŒå¤±æ•—ã—ã¾ã—ãŸãŒã€å–å¾—ã—ãŸãƒˆãƒ¬ãƒ³ãƒ‰ã‚’ç›´æ¥è¡¨ç¤ºã—ã¾ã™ã€‚")
                        fallback_recs = []
                        for item in google_items[:10]:
                            fallback_recs.append({
                                "title": item["title"],
                                "reason": item.get("source", ""),
                                "angle": "ç›´æ¥å–å¾—ï¼ˆAIé¸å®šã‚¹ã‚­ãƒƒãƒ—ï¼‰",
                                "pillars": [],
                                "hook_type": "",
                                "score": 70,
                            })
                        if fallback_recs:
                            st.session_state.ai_recommendations = fallback_recs
                            st.session_state.related_news = {}
                            st.session_state.trend_step = 2
                            st.rerun()

    # â”€â”€ STEP 2: ãƒˆãƒ”ãƒƒã‚¯é¸æŠ â”€â”€
    has_x = bool(st.session_state.get("x_trend_items"))
    has_ai = bool(st.session_state.get("ai_recommendations"))
    has_yahoo = bool(st.session_state.get("yahoo_items"))

    if has_x or has_ai or has_yahoo:
        st.markdown("---")
        st.markdown("### â‘¡ ãƒˆãƒ”ãƒƒã‚¯ã‚’é¸æŠ")
        st.caption("ãƒã‚¹ãƒˆã«ã—ãŸã„ãƒˆãƒ”ãƒƒã‚¯ã«ãƒã‚§ãƒƒã‚¯ã‚’å…¥ã‚Œã¦ãã ã•ã„ã€‚")

        selected = []
        rec_idx = 0

        # æ‰‹å‹•ãƒˆãƒ”ãƒƒã‚¯
        if st.session_state.get("manual_topics"):
            st.markdown("**âœï¸ æ‰‹å‹•è¿½åŠ ãƒˆãƒ”ãƒƒã‚¯:**")
            for j, mt in enumerate(st.session_state.manual_topics):
                if st.checkbox(f"âœï¸ {mt}", key=f"manual_{j}", value=True):
                    selected.append({"title": mt, "angle": "æ‰‹å‹•å…¥åŠ›", "pillars": [], "hook_type": ""})

        # â”€â”€ ğŸ¦ Xãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆãƒ¡ã‚¤ãƒ³ï¼‰ â”€â”€
        if has_x:
            x_items = st.session_state.x_trend_items
            st.markdown(f"#### ğŸ¦ Xãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆ{len(x_items)}ä»¶ï¼‰")
            st.caption("Xã®ã€Œè©±é¡Œã‚’æ¤œç´¢ã€â†’ ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¿ãƒ–ã‹ã‚‰å–å¾—ã€‚ä»ŠXä¸Šã§æœ€ã‚‚è©±é¡Œã«ãªã£ã¦ã„ã‚‹ãƒ‹ãƒ¥ãƒ¼ã‚¹ã§ã™ã€‚")

            for item in x_items:
                label = f"ğŸ¦ {item['title']}"
                checked = st.checkbox(label, key=f"x_news_{rec_idx}", value=False)
                if checked:
                    selected.append({
                        "title": item["title"],
                        "angle": "Xãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒˆãƒ¬ãƒ³ãƒ‰",
                        "pillars": [],
                        "hook_type": "ãƒˆãƒ¬ãƒ³ãƒ‰èµ·ç‚¹",
                        "score": 90,
                    })
                rec_idx += 1

        # â”€â”€ ğŸŒ ä¸–ã®ä¸­ã®ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆAIé¸å®šï¼‰ â”€â”€
        if has_ai:
            recs = st.session_state.ai_recommendations
            st.markdown(f"#### ğŸŒ ä¸–ã®ä¸­ã®ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆAIå³é¸ {len(recs)}ä»¶ï¼‰")
            st.caption("Google Newsã‹ã‚‰ã™ã‚ã—ç¤¾é•·å‘ãã®ãƒˆãƒ”ãƒƒã‚¯ã‚’AIãŒå³é¸ã€‚")

            def _show_rec(rec, idx, default_checked=False):
                """æ¨è–¦ã‚«ãƒ¼ãƒ‰ã‚’è¡¨ç¤ºã—ã¦é¸æŠçŠ¶æ…‹ã‚’è¿”ã™"""
                pillars_str = " Ã— ".join(rec.get("pillars", []))
                hook_str = rec.get("hook_type", "")
                score = rec.get("score", 0)
                if score >= 90: badge = "ğŸ”¥"
                elif score >= 80: badge = "â­"
                else: badge = "ğŸ“Œ"
                checked = st.checkbox(f"{badge} **{rec['title']}**", key=f"rec_{idx}", value=default_checked)
                st.markdown(f"""<div class="trend-card">
    <div class="trend-title">{rec['title']}</div>
    <div class="trend-source">ğŸ·ï¸ {pillars_str}ã€€ï½œã€€ğŸ£ {hook_str}ã€€ï½œã€€ğŸ“Š ç›¸æ€§åº¦: {score}/100</div>
    <div class="trend-reason">ğŸ’¡ {rec.get('angle', '')}</div>
</div>""", unsafe_allow_html=True)
                rel = st.session_state.get("related_news", {}).get(rec["title"], [])
                if rel:
                    with st.expander(f"ğŸ“° é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ ({len(rel)}ä»¶)", expanded=False):
                        for art in rel:
                            st.caption(f"â€¢ {art['title']}ï¼ˆ{art['source']}ï¼‰")
                return checked

            first_ai_idx = rec_idx
            for rec in recs:
                if _show_rec(rec, rec_idx, default_checked=(rec_idx == first_ai_idx and not has_x)):
                    selected.append(rec)
                rec_idx += 1

        # â”€â”€ ğŸ” Yahoo!ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è£œè¶³ â”€â”€
        if has_yahoo:
            yahoo_items = st.session_state.yahoo_items
            with st.expander(f"ğŸ” Yahoo!ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è£œè¶³ï¼ˆ{len(yahoo_items)}ä»¶ï¼‰", expanded=False):
                st.caption("Yahoo!ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œç´¢ã‹ã‚‰ã®è£œè¶³æƒ…å ±ã€‚Xä¸Šã§ä»Šè©±é¡Œã®ãƒã‚¹ãƒˆã‚’å‚è€ƒã«ã§ãã¾ã™ã€‚")

                categories = {}
                for item in yahoo_items:
                    cat = item.get("category", "ãã®ä»–")
                    if cat not in categories:
                        categories[cat] = []
                    categories[cat].append(item)

                for cat, items in categories.items():
                    st.markdown(f"**{cat}**")
                    for item in items:
                        label = f"ğŸ” {item['title']}"
                        checked = st.checkbox(label, key=f"yahoo_{rec_idx}", value=False)
                        if item.get("full_text") and item["full_text"] != item["title"]:
                            st.caption(f"ğŸ’¬ {item['full_text'][:120]}")
                        if checked:
                            selected.append({
                                "title": item["title"],
                                "angle": f"Yahoo!ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ï¼ˆ{cat}ï¼‰",
                                "pillars": [],
                                "hook_type": "ãƒˆãƒ¬ãƒ³ãƒ‰èµ·ç‚¹",
                                "score": 70,
                                "full_text": item.get("full_text", ""),
                            })
                        rec_idx += 1

        # è¿½åŠ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
        extra = st.text_area("ğŸ“Œ è¿½åŠ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆä»»æ„ï¼‰", height=80,
            placeholder="é–¢é€£ã™ã‚‹åŸç¨¿ã‚„è¿½åŠ æƒ…å ±...", key="trend_extra")

        # ä¿®æ­£æŒ‡ç¤º
        modify_instruction = st.text_area("âœï¸ ä¿®æ­£æŒ‡ç¤ºï¼ˆä»»æ„ï¼‰", height=80,
            placeholder="ä¾‹: ã‚‚ã£ã¨å‰å‘ãã«ã€è‹¥è€…å‘ã‘ã®èªã‚Šå£ã§ã€ç±³å›½ã¨ã®æ¯”è¼ƒã‚’å…¥ã‚Œã¦...", key="trend_modify")

        if selected:
            if st.button("ğŸ¤– ã™ã‚ã—ç¤¾é•·ã‚¹ã‚¿ã‚¤ãƒ«ã®ãƒã‚¹ãƒˆã‚’ç”Ÿæˆ", type="primary", use_container_width=True, key="gen_btn"):
                system_prompt = load_system_prompt()
                gen_progress = st.empty()

                # â”€â”€ STEP A: é¸æŠãƒˆãƒ”ãƒƒã‚¯ã®æœ€æ–°æƒ…å ±ã‚’Webæ¤œç´¢ â”€â”€
                gen_progress.info("ğŸ” é¸æŠãƒˆãƒ”ãƒƒã‚¯ã®æœ€æ–°æƒ…å ±ã‚’Webæ¤œç´¢ä¸­...")
                topic_facts = search_facts_for_topics(selected, progress=gen_progress)

                # é¸æŠãƒˆãƒ”ãƒƒã‚¯ã®æƒ…å ±ã‚’æ§‹ç¯‰ï¼ˆæ¤œç´¢çµæœä»˜ãï¼‰
                topics_context = ""
                for s in selected:
                    topics_context += f"\n### ãƒˆãƒ”ãƒƒã‚¯: {s['title']}\n"
                    if s.get("angle"):
                        topics_context += f"- åˆ‡ã‚Šå£: {s['angle']}\n"
                    if s.get("pillars"):
                        topics_context += f"- æŸ±ã®çµ„åˆã›: {' Ã— '.join(s['pillars'])}\n"
                    if s.get("hook_type"):
                        topics_context += f"- ãƒ•ãƒƒã‚¯å‹: {s['hook_type']}\n"
                    # é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹
                    rel = st.session_state.get("related_news", {}).get(s["title"], [])
                    if rel:
                        topics_context += "- é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹:\n"
                        for art in rel:
                            topics_context += f"  - {art['title']}ï¼ˆ{art['source']}ï¼‰\n"
                    # Webæ¤œç´¢çµæœã‚’è¿½åŠ 
                    clean_title = re.sub(r'\s*\(\d[\d,]*ä»¶ã®ãƒã‚¹ãƒˆ\)', '', s['title']).strip()
                    facts = topic_facts.get(clean_title, [])
                    if facts:
                        topics_context += "- æœ€æ–°ã®Webæ¤œç´¢çµæœï¼ˆäº‹å®Ÿç¢ºèªç”¨ï¼‰:\n"
                        for fact in facts:
                            topics_context += f"  - {fact}\n"

                # â”€â”€ STEP A.5: ãƒˆãƒ”ãƒƒã‚¯æ–¹å‘æ€§åˆ†æ â”€â”€
                gen_progress.info("ğŸ¯ ãƒˆãƒ”ãƒƒã‚¯ã«æœ€é©ãªåˆ‡ã‚Šå£ã‚’åˆ†æä¸­...")
                all_search_text_for_analysis = ""
                for facts_list in topic_facts.values():
                    all_search_text_for_analysis += "\n".join(facts_list) + "\n"
                angle_directions = analyze_topic_angles(topics_context, all_search_text_for_analysis)

                # â”€â”€ STEP B: ãƒã‚¹ãƒˆç”Ÿæˆ â”€â”€
                gen_progress.info("ğŸ¤– ã™ã‚ã—ç¤¾é•·ã‚¹ã‚¿ã‚¤ãƒ«ã®ãƒã‚¹ãƒˆã‚’ç”Ÿæˆä¸­...")
                user_msg = f"""ä»¥ä¸‹ã®ãƒˆãƒ”ãƒƒã‚¯ã«ã¤ã„ã¦ã€ã™ã‚ã—ç¤¾é•·ã‚¹ã‚¿ã‚¤ãƒ«ã®Xãƒã‚¹ãƒˆã‚’3æ¡ˆç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
å„æ¡ˆ600ã€œ800æ–‡å­—ã§ã€ãã‚Œãã‚Œç•°ãªã‚‹åˆ‡ã‚Šå£ã§ä»•çµ„ã¿ãƒ»æ§‹é€ ã‚’è§£èª¬ã™ã‚‹ã‚¹ã‚¿ã‚¤ãƒ«ã«ã—ã¦ãã ã•ã„ã€‚

â–  ç”Ÿæˆã™ã‚‹3æ¡ˆï¼ˆå„600ã€œ800æ–‡å­—ï¼‰:
ã€æ¡ˆ1ã€‘ä»•çµ„ã¿ã‚„æ­´å²è§£èª¬å‹ â€” ãƒ†ãƒ¼ãƒã®åŸºæœ¬æ§‹é€ ã‚’æ•´ç†ã—ã¦ã€Œãªãœãã†ãªã‚‹ã®ã‹ã€ã‚’è§£ãæ˜ã‹ã™
ã€æ¡ˆ2ã€‘å›½éš›æ¯”è¼ƒå‹ â€” ä»–å›½ã®äº‹ä¾‹ã¨æ¯”è¼ƒã—ã¦æ—¥æœ¬ã®çŠ¶æ³ã‚’ç«‹ä½“çš„ã«è¦‹ã›ã‚‹
ã€æ¡ˆ3ã€‘é‹­ã„è€ƒå¯Ÿãƒ»ä»Šå¾Œã®ã‚·ãƒŠãƒªã‚ªå‹ â€” ãƒ†ãƒ¼ãƒã®æœ¬è³ªã‚’é‹­ãåˆ†æã—ã€ä»Šå¾Œã®å±•é–‹ã‚·ãƒŠãƒªã‚ªã‚’æç¤ºã™ã‚‹
"""
                if angle_directions:
                    user_msg += f"""
â–  å„æ¡ˆã®æ–¹å‘æ€§ï¼ˆã“ã®æ–¹å‘æ€§ã«æ²¿ã£ã¦æ›¸ã„ã¦ãã ã•ã„ï¼‰:
{angle_directions}
"""
                user_msg += f"""
â–  é¸å®šã•ã‚ŒãŸãƒˆãƒ”ãƒƒã‚¯:
{topics_context}

â–  é‡è¦ãªæŒ‡ç¤ºï¼ˆå¿…ãšå®ˆã‚‹ã“ã¨ï¼‰:
- ã€1æ–‡ç›®ã€‘èª­è€…ã®èˆˆå‘³ã‚’å¼·ãå¼•ãä¸€æ–‡ã§å§‹ã‚ã‚‹ï¼ˆæ„å¤–ãªæ•°å­—ã€é€†èª¬çš„ãªå•ã„ã€é©šãã®äº‹å®Ÿãªã©ï¼‰
- ã€å‰åŠã€‘1æ–‡ç›®ã®å¾Œã™ãã«ã€ã“ã®è©±ã®å‰æã¨ãªã‚‹çŸ¥è­˜ã‚„èƒŒæ™¯ã‚’ç°¡æ½”ã«ã‚ã‹ã‚Šã‚„ã™ãèª¬æ˜ã™ã‚‹ã€‚èª­è€…ãŒã€Œãªãœã“ã‚ŒãŒé‡è¦ãªã®ã‹ã€ã‚’ç†è§£ã§ãã¦ã‹ã‚‰æœ¬é¡Œã«å…¥ã‚‹ã“ã¨
- ã€Œãƒ‹ãƒ¥ãƒ¼ã‚¹ã®æ„Ÿæƒ³ã€ã§ã¯ãªãã€Œä»•çµ„ã¿ãƒ»æ§‹é€ ã®è§£èª¬ã€ã¨ã—ã¦æ›¸ãã“ã¨
- å…·ä½“çš„ãªæ•°å­—ã¯å¿…ãšæ¯”è¼ƒã‚»ãƒƒãƒˆã§ä½¿ã†ï¼ˆã€ŒAã¯â—‹ï¼…ãªã®ã«ã€Bã¯â–³ï¼…ã€ï¼‰
- ã€Œãªãœãã†ãªã‚‹ã®ã‹ã€ã®ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’å¿…ãšè§£èª¬ã™ã‚‹ã“ã¨
- ä»–å›½ã®å…·ä½“çš„ãªå›½åãƒ»äººåãƒ»åˆ¶åº¦åã‚’å…¥ã‚Œã‚‹ã“ã¨
- ç· ã‚ã¯ä¸»å¼µã§ã¯ãªãã€ç¤ºå”†ãƒ»å•ã„ã‹ã‘ã§ä½™éŸ»ã‚’æ®‹ã™ã“ã¨
- ã€Œæœ€æ–°ã®Webæ¤œç´¢çµæœã€ã®æƒ…å ±ã‚’å¿…ãšå‚ç…§ã—ã€äº‹å®Ÿã«åŸºã¥ã„ãŸæ­£ç¢ºãªè¨˜è¿°ã«ã™ã‚‹ã“ã¨
- ç¾åœ¨ã®ç±³å›½å¤§çµ±é ˜ã¯ãƒ‰ãƒŠãƒ«ãƒ‰ãƒ»ãƒˆãƒ©ãƒ³ãƒ—ï¼ˆç¬¬2æœŸã€2025å¹´1æœˆå°±ä»»ï¼‰ã§ã™
- äººåãƒ»æ”¿æ¨©åãƒ»æ•°å€¤ãªã©ã®äº‹å®Ÿæƒ…å ±ã¯æ¤œç´¢çµæœã«åŸºã¥ãæ­£ç¢ºã«è¨˜è¿°ã™ã‚‹ã“ã¨
"""
                if extra.strip():
                    user_msg += f"\nâ–  è¿½åŠ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ:\n{extra}\n"
                if modify_instruction.strip():
                    user_msg += f"\nâ–  ä¿®æ­£æŒ‡ç¤ºï¼ˆã“ã‚Œã‚’æœ€å„ªå…ˆã§åæ˜ ã—ã¦ãã ã•ã„ï¼‰:\n{modify_instruction}\n"

                enhanced_system = system_prompt + ENHANCED_GENERATION_PROMPT
                result = generate_with_claude(
                    messages=[{"role": "user", "content": user_msg}],
                    system_prompt=enhanced_system,
                )

                # â”€â”€ STEP C: ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ â”€â”€
                gen_progress.info("ğŸ” ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ä¸­...")
                # å„æ¡ˆã‚’è§£æã—ã¦ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯
                posts = parse_generated_posts(result)
                all_search_text = ""
                for facts_list in topic_facts.values():
                    all_search_text += "\n".join(facts_list) + "\n"

                fc_results = {}
                for post in posts:
                    fc = run_factcheck(post["body"], all_search_text)
                    if fc:
                        fc_results[post["number"]] = fc

                # â”€â”€ STEP D: ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯çµæœã«åŸºã¥ãè‡ªå‹•ä¿®æ­£ â”€â”€
                corrected_result = result
                corrections_applied = False
                if any(_factcheck_has_issues(fc) for fc in fc_results.values()):
                    gen_progress.info("âœï¸ ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯çµæœã«åŸºã¥ã„ã¦ãƒã‚¹ãƒˆã‚’ä¿®æ­£ä¸­...")
                    corrected_posts_text = []
                    for post in posts:
                        fc = fc_results.get(post["number"])
                        if fc and _factcheck_has_issues(fc):
                            corrected_body = auto_correct_post(post["body"], fc, all_search_text)
                            corrected_posts_text.append(
                                f"ã€æ¡ˆ{post['number']}ã€‘{post.get('title', '')}\n{corrected_body}"
                            )
                            corrections_applied = True
                        else:
                            corrected_posts_text.append(
                                f"ã€æ¡ˆ{post['number']}ã€‘{post.get('title', '')}\n{post['body']}"
                            )
                    corrected_result = "\n\n".join(corrected_posts_text)

                gen_progress.empty()
                st.session_state.trend_result = corrected_result
                st.session_state.trend_result_original = result
                st.session_state.trend_factcheck = fc_results
                st.session_state.trend_corrections_applied = corrections_applied
                st.session_state.trend_step = 3
                save_history("trend", {
                    "selected_topics": [s["title"] for s in selected],
                    "angles": [s.get("angle", "") for s in selected],
                    "extra": extra,
                }, corrected_result)
                _autosave()
                st.rerun()

    # â”€â”€ STEP 3: çµæœ â”€â”€
    if st.session_state.get("trend_result") and st.session_state.get("trend_step", 1) >= 3:
        st.markdown("---")
        corrections_applied = st.session_state.get("trend_corrections_applied", False)
        if corrections_applied:
            st.markdown("### â‘¢ âœ¨ ç”Ÿæˆçµæœï¼ˆãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ä¿®æ­£æ¸ˆã¿ âœ…ï¼‰")
            st.success("ğŸ” ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ã§æ¤œå‡ºã•ã‚ŒãŸå•é¡Œã‚’è‡ªå‹•ä¿®æ­£ã—ã¾ã—ãŸ")
        else:
            st.markdown("### â‘¢ âœ¨ ç”Ÿæˆçµæœï¼ˆãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯æ¸ˆã¿ âœ…ï¼‰")
        display_generated_results(st.session_state.trend_result, "trend")

        # ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯è©³ç´°
        fc_results = st.session_state.get("trend_factcheck", {})
        if fc_results:
            with st.expander("ğŸ” ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯è©³ç´°", expanded=False):
                if corrections_applied:
                    st.info("ä»¥ä¸‹ã¯åˆå›ç”Ÿæˆæ™‚ã®ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯çµæœã§ã™ã€‚å•é¡Œç®‡æ‰€ã¯è‡ªå‹•ä¿®æ­£æ¸ˆã¿ã§ã™ã€‚")
                for num, fc_text in fc_results.items():
                    st.markdown(f"**æ¡ˆ{num}:**")
                    st.markdown(fc_text)
                    st.markdown("---")
        if corrections_applied:
            with st.expander("ğŸ“ ä¿®æ­£å‰ã®å…ƒãƒ†ã‚­ã‚¹ãƒˆ", expanded=False):
                st.text(st.session_state.get("trend_result_original", ""))

        c1, c2 = st.columns(2)
        _trend_clear_keys = [
            "trend_result", "trend_result_original", "trend_corrections_applied",
            "ai_recommendations", "raw_news", "related_news",
            "trend_step", "manual_topics", "x_trend_items", "yahoo_items",
            "trend_revision", "trend_selected_post", "trend_factcheck",
        ]
        # å›³è§£ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚‚å‰Šé™¤
        for sk in list(st.session_state.keys()):
            if sk.startswith("infographic_trend_"):
                _trend_clear_keys.append(sk)
        with c1:
            if st.button("ğŸ—‘ï¸ ã‚¯ãƒªã‚¢", key="cl_t"):
                for k in _trend_clear_keys:
                    st.session_state.pop(k, None)
                _autosave()
                st.rerun()
        with c2:
            if st.button("ğŸ”„ æ–°ã—ã„ãƒˆãƒ¬ãƒ³ãƒ‰", key="new_t"):
                for k in _trend_clear_keys:
                    st.session_state.pop(k, None)
                _autosave()
                st.rerun()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ã‚¿ãƒ–2: åŸç¨¿å¤‰æ›
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with tab2:
    st.markdown("#### YouTubeåŸç¨¿ã‹ã‚‰Xãƒã‚¹ãƒˆã‚’ç”Ÿæˆ")
    script_text = st.text_area("ğŸ“„ åŸç¨¿ãƒ†ã‚­ã‚¹ãƒˆ", height=250, placeholder="YouTubeå‹•ç”»ã®åŸç¨¿ã‚’ã“ã“ã«...", key="s_in")
    script_ctx = st.text_area("ğŸ“Œ è¿½åŠ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆä»»æ„ï¼‰", height=80, placeholder="é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ç­‰...", key="s_ctx")
    if st.button("â–¶ ç”Ÿæˆã™ã‚‹", key="g_s", type="primary", use_container_width=True):
        if not script_text.strip():
            st.warning("åŸç¨¿ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        else:
            sp = load_system_prompt() + ENHANCED_GENERATION_PROMPT
            msg = f"""ä»¥ä¸‹ã®YouTubeåŸç¨¿ã‚’ãƒ™ãƒ¼ã‚¹ã«ã€ã™ã‚ã—ç¤¾é•·ã‚¹ã‚¿ã‚¤ãƒ«ã®Xãƒã‚¹ãƒˆã‚’3æ¡ˆç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
ãã‚Œãã‚Œ600ã€œ800æ–‡å­—ã§ã€åˆ‡ã‚Šå£ã‚„ãƒ•ãƒƒã‚¯ã‚’å¤‰ãˆã¦ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä»˜ã‘ã¦ãã ã•ã„ã€‚
å“è³ªã‚¹ã‚³ã‚¢ãŒæœ€å¤§ã«ãªã‚‹ã‚ˆã†æ„è­˜ã—ã¦ãã ã•ã„ã€‚

ã€æ¡ˆ1ã€‘åˆ‡ã‚Šå£Aï¼ˆ600ã€œ800æ–‡å­—ï¼‰
ã€æ¡ˆ2ã€‘åˆ‡ã‚Šå£Bï¼ˆ600ã€œ800æ–‡å­—ï¼‰
ã€æ¡ˆ3ã€‘åˆ‡ã‚Šå£Cï¼ˆ600ã€œ800æ–‡å­—ï¼‰

â–  åŸç¨¿:
{script_text}
"""
            if script_ctx.strip(): msg += f"\nâ–  è¿½åŠ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ:\n{script_ctx}\n"
            result = generate_with_claude([{"role": "user", "content": msg}], sp)
            # ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯
            posts = parse_generated_posts(result)
            fc_results = {}
            for post in posts:
                fc = run_factcheck(post["body"])
                if fc:
                    fc_results[post["number"]] = fc
            # è‡ªå‹•ä¿®æ­£
            corrected_result = result
            scr_corrections = False
            if any(_factcheck_has_issues(fc) for fc in fc_results.values()):
                corrected_posts_text = []
                for post in posts:
                    fc = fc_results.get(post["number"])
                    if fc and _factcheck_has_issues(fc):
                        corrected_body = auto_correct_post(post["body"], fc)
                        corrected_posts_text.append(f"ã€æ¡ˆ{post['number']}ã€‘{post.get('title', '')}\n{corrected_body}")
                        scr_corrections = True
                    else:
                        corrected_posts_text.append(f"ã€æ¡ˆ{post['number']}ã€‘{post.get('title', '')}\n{post['body']}")
                corrected_result = "\n\n".join(corrected_posts_text)
            st.session_state.script_result = corrected_result
            st.session_state.script_result_original = result
            st.session_state.script_factcheck = fc_results
            st.session_state.script_corrections = scr_corrections
            save_history("script", {"script": script_text[:200], "context": script_ctx}, corrected_result)
            _autosave()
    if st.session_state.get("script_result"):
        st.markdown("---")
        scr_corr = st.session_state.get("script_corrections", False)
        if scr_corr:
            st.markdown("## âœ¨ ç”Ÿæˆçµæœï¼ˆãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ä¿®æ­£æ¸ˆã¿ âœ…ï¼‰")
            st.success("ğŸ” ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ã§æ¤œå‡ºã•ã‚ŒãŸå•é¡Œã‚’è‡ªå‹•ä¿®æ­£ã—ã¾ã—ãŸ")
        else:
            st.markdown("## âœ¨ ç”Ÿæˆçµæœï¼ˆãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯æ¸ˆã¿ âœ…ï¼‰")
        display_generated_results(st.session_state.script_result, "scr")
        fc_results = st.session_state.get("script_factcheck", {})
        if fc_results:
            with st.expander("ğŸ” ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯è©³ç´°", expanded=False):
                if scr_corr:
                    st.info("å•é¡Œç®‡æ‰€ã¯è‡ªå‹•ä¿®æ­£æ¸ˆã¿ã§ã™ã€‚")
                for num, fc_text in fc_results.items():
                    st.markdown(f"**æ¡ˆ{num}:**")
                    st.markdown(fc_text)
                    st.markdown("---")
        if st.button("ğŸ—‘ï¸ ã‚¯ãƒªã‚¢", key="cl_s"):
            clear_keys = ["script_result", "script_result_original", "script_corrections",
                          "scr_revision", "scr_selected_post", "script_factcheck"]
            for sk in list(st.session_state.keys()):
                if sk.startswith("infographic_scr_"):
                    clear_keys.append(sk)
            for k in clear_keys:
                st.session_state.pop(k, None)
            _autosave()
            st.rerun()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ã‚¿ãƒ–3: ç”»åƒã‚³ãƒ¡ãƒ³ãƒˆ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with tab3:
    st.markdown("#### ç”»åƒã«ã™ã‚ã—ç¤¾é•·ã‚¹ã‚¿ã‚¤ãƒ«ã®ã‚³ãƒ¡ãƒ³ãƒˆ")
    img = st.file_uploader("ğŸ–¼ï¸ ç”»åƒ", type=["png","jpg","jpeg","gif","webp"], key="img_up")
    if img: st.image(img, caption=img.name, width=400)
    img_desc = st.text_area("ğŸ“Œ èª¬æ˜ï¼ˆä»»æ„ï¼‰", height=80, placeholder="èƒŒæ™¯ã‚„æ–‡è„ˆ...", key="img_d")
    if st.button("â–¶ ã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆ", key="g_i", type="primary", use_container_width=True):
        if not img:
            st.warning("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        else:
            sp = load_system_prompt() + ENHANCED_GENERATION_PROMPT
            img_bytes = img.read(); img.seek(0)
            img_b64 = base64.b64encode(img_bytes).decode()
            ext = img.name.rsplit(".",1)[-1].lower()
            mime = {"jpg":"image/jpeg","jpeg":"image/jpeg","png":"image/png","gif":"image/gif","webp":"image/webp"}.get(ext,"image/png")
            desc = f"\nâ–  èª¬æ˜:\n{img_desc}\n" if img_desc.strip() else ""
            content = [
                {"type": "text", "text": f"""ä»¥ä¸‹ã®ç”»åƒã«ã¤ã„ã¦ã€ã™ã‚ã—ç¤¾é•·ã‚¹ã‚¿ã‚¤ãƒ«ã®Xãƒã‚¹ãƒˆã‚’3æ¡ˆç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
ãã‚Œãã‚Œ600ã€œ800æ–‡å­—ã§ã€åˆ‡ã‚Šå£ã‚’å¤‰ãˆã¦ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä»˜ã‘ã¦ãã ã•ã„ã€‚

ã€æ¡ˆ1ã€‘åˆ‡ã‚Šå£Aï¼ˆ600ã€œ800æ–‡å­—ï¼‰
ã€æ¡ˆ2ã€‘åˆ‡ã‚Šå£Bï¼ˆ600ã€œ800æ–‡å­—ï¼‰
ã€æ¡ˆ3ã€‘åˆ‡ã‚Šå£Cï¼ˆ600ã€œ800æ–‡å­—ï¼‰
{desc}
ç”»åƒæ·»ä»˜å‰æã®ãƒã‚¹ãƒˆã«ã—ã¦ãã ã•ã„ã€‚"""},
                {"type": "image", "source": {"type": "base64", "media_type": mime, "data": img_b64}},
            ]
            result = generate_with_claude([{"role": "user", "content": content}], sp)
            # ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯
            posts = parse_generated_posts(result)
            fc_results = {}
            for post in posts:
                fc = run_factcheck(post["body"])
                if fc:
                    fc_results[post["number"]] = fc
            # è‡ªå‹•ä¿®æ­£
            corrected_result = result
            img_corrections = False
            if any(_factcheck_has_issues(fc) for fc in fc_results.values()):
                corrected_posts_text = []
                for post in posts:
                    fc = fc_results.get(post["number"])
                    if fc and _factcheck_has_issues(fc):
                        corrected_body = auto_correct_post(post["body"], fc)
                        corrected_posts_text.append(f"ã€æ¡ˆ{post['number']}ã€‘{post.get('title', '')}\n{corrected_body}")
                        img_corrections = True
                    else:
                        corrected_posts_text.append(f"ã€æ¡ˆ{post['number']}ã€‘{post.get('title', '')}\n{post['body']}")
                corrected_result = "\n\n".join(corrected_posts_text)
            st.session_state.image_result = corrected_result
            st.session_state.image_result_original = result
            st.session_state.image_factcheck = fc_results
            st.session_state.image_corrections = img_corrections
            save_history("image", {"image_name": img.name, "desc": img_desc}, corrected_result)
            _autosave()
    if st.session_state.get("image_result"):
        st.markdown("---")
        img_corr = st.session_state.get("image_corrections", False)
        if img_corr:
            st.markdown("## âœ¨ ç”Ÿæˆçµæœï¼ˆãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ä¿®æ­£æ¸ˆã¿ âœ…ï¼‰")
            st.success("ğŸ” ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯ã§æ¤œå‡ºã•ã‚ŒãŸå•é¡Œã‚’è‡ªå‹•ä¿®æ­£ã—ã¾ã—ãŸ")
        else:
            st.markdown("## âœ¨ ç”Ÿæˆçµæœï¼ˆãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯æ¸ˆã¿ âœ…ï¼‰")
        display_generated_results(st.session_state.image_result, "img")
        fc_results = st.session_state.get("image_factcheck", {})
        if fc_results:
            with st.expander("ğŸ” ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯è©³ç´°", expanded=False):
                if img_corr:
                    st.info("å•é¡Œç®‡æ‰€ã¯è‡ªå‹•ä¿®æ­£æ¸ˆã¿ã§ã™ã€‚")
                for num, fc_text in fc_results.items():
                    st.markdown(f"**æ¡ˆ{num}:**")
                    st.markdown(fc_text)
                    st.markdown("---")
        if st.button("ğŸ—‘ï¸ ã‚¯ãƒªã‚¢", key="cl_i"):
            clear_keys = ["image_result", "image_result_original", "image_corrections",
                          "img_revision", "img_selected_post", "image_factcheck"]
            for sk in list(st.session_state.keys()):
                if sk.startswith("infographic_img_"):
                    clear_keys.append(sk)
            for k in clear_keys:
                st.session_state.pop(k, None)
            _autosave()
            st.rerun()
